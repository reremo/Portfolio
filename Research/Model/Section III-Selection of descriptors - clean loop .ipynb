{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#These are store after running the \"Data preprocessing\" notebook\n",
    "\n",
    "%store -r df_qsar\n",
    "%store -r X_train          \n",
    "%store  -r X_test  \n",
    "%store -r y_train\n",
    "%store -r  y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r X\n",
    "%store -r X_df\n",
    "%store -r log_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(299, 736)\n",
      "(299, 3)\n"
     ]
    }
   ],
   "source": [
    "print (X.shape)\n",
    "print (log_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn import svm\n",
    "from sklearn import pipeline\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn import model_selection\n",
    "from math import sqrt\n",
    "\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn import linear_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-8-5c22210b8388>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-8-5c22210b8388>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    conda install scikit-learn==0.21\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "conda install scikit-learn==0.21\n",
    "from genetic_selection import GeneticSelectionCV\n",
    "\n",
    "#If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+\n",
    "#I need to modify the GeneticSelectionCV code. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define mean squared error as the score \n",
    "###### !Later the sqrt of the score will be calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_scorer = make_scorer(mean_squared_error, greater_is_better=False)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Define genetic algorithm as the selector and fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_DCAA_rf = Pipeline(\n",
    "    [\n",
    "        ('std_scaler', StandardScaler()),\n",
    "        (\"RF\", RandomForestRegressor(random_state = 17,\n",
    "                                    n_estimators = 100,\n",
    "                                    max_features = \"auto\",\n",
    "                                    min_samples_split = 0.03,\n",
    "                                    min_samples_leaf = 0.01,\n",
    "                                    max_depth = 10,\n",
    "                                    max_leaf_nodes = None,\n",
    "                                    n_jobs = 1))\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe_TCAA_rf = Pipeline(\n",
    "    [\n",
    "        ('std_scaler', StandardScaler()),\n",
    "        (\"RF\", RandomForestRegressor(random_state = 17,\n",
    "                                    n_estimators = 100,\n",
    "                                    max_features = \"auto\",\n",
    "                                     min_samples_split = 2,\n",
    "                                     min_samples_leaf = 1,\n",
    "                                     max_depth = 30,\n",
    "                                     max_leaf_nodes = None,\n",
    "                                    n_jobs = 1))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_DCAA_svr = Pipeline(\n",
    "    [\n",
    "        ('std_scaler', StandardScaler()),\n",
    "        (\"SVR\", SVR(C=6,\n",
    "                    epsilon=0.0003,\n",
    "                    gamma=0.003,\n",
    "                    kernel='rbf',\n",
    "                    max_iter=-1,\n",
    "                    shrinking=True,\n",
    "                    tol=0.001,\n",
    "                    verbose=False))\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe_TCAA_svr = Pipeline(\n",
    "    [\n",
    "        ('std_scaler', StandardScaler()),\n",
    "        (\"SVR\", SVR(C=3,\n",
    "                    epsilon=0.3,\n",
    "                    gamma=0.001,\n",
    "                    kernel='rbf',\n",
    "                    max_iter=-1,\n",
    "                    shrinking=True,\n",
    "                    tol=0.001,\n",
    "                    verbose=False))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_list = [3,5,10,20,50,100,200,400,732]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_list = [5,10,20,50,100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_list = [5,10, 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_list = [None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### A new dictionary of selectors is defined using mse as scorer\n",
    "\n",
    "selector_mse_DCAA_rf = dict()\n",
    "selector_mse_DCAA_svr = dict()\n",
    "\n",
    "for a in max_list:\n",
    "    selector_mse_DCAA_rf[a] = GeneticSelectionCV(pipe_DCAA_rf,\n",
    "                                  cv=5,\n",
    "                                  verbose=1,\n",
    "                                  scoring=rmse_scorer,\n",
    "                                  max_features= a,\n",
    "                                  n_population=1464,\n",
    "                                  crossover_proba=0.5,\n",
    "                                  mutation_proba=0.02,\n",
    "                                  n_generations=10,\n",
    "                                  crossover_independent_proba=0.5,\n",
    "                                  mutation_independent_proba=0.02,\n",
    "                                  tournament_size=5,\n",
    "                                  n_gen_no_change=10,\n",
    "                                  caching=True,\n",
    "                                  n_jobs=-1)\n",
    "    selector_mse_DCAA_svr[a] = GeneticSelectionCV(pipe_DCAA_svr,\n",
    "                                  cv=5,\n",
    "                                  verbose=1,\n",
    "                                  scoring=rmse_scorer,\n",
    "                                  max_features= a,\n",
    "                                  n_population=1464,\n",
    "                                  crossover_proba=0.5,\n",
    "                                  mutation_proba=0.02,\n",
    "                                  n_generations=55,\n",
    "                                  crossover_independent_proba=0.5,\n",
    "                                  mutation_independent_proba=0.02,\n",
    "                                  tournament_size=5,\n",
    "                                  n_gen_no_change=55,\n",
    "                                  caching=True,\n",
    "                                  n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A new dictionary of selectors is defined using mse as scorer\n",
    "\n",
    "selector_mse_TCAA_rf = dict()\n",
    "selector_mse_TCAA_svr = dict()\n",
    "\n",
    "for a in max_list:\n",
    "    selector_mse_TCAA_rf[a] = GeneticSelectionCV(pipe_TCAA_rf,\n",
    "                                  cv=5,\n",
    "                                  verbose=1,\n",
    "                                  scoring=rmse_scorer,\n",
    "                                  max_features= a,\n",
    "                                  n_population=1464,\n",
    "                                  crossover_proba=0.5,\n",
    "                                  mutation_proba=0.02,\n",
    "                                  n_generations=10,\n",
    "                                  crossover_independent_proba=0.5,\n",
    "                                  mutation_independent_proba=0.02,\n",
    "                                  tournament_size=5,\n",
    "                                  n_gen_no_change=10,\n",
    "                                  caching=True,\n",
    "                                  n_jobs=-1)\n",
    "    \n",
    "    selector_mse_TCAA_svr[a] = GeneticSelectionCV(pipe_TCAA_svr,\n",
    "                                  cv=5,\n",
    "                                  verbose=1,\n",
    "                                  scoring=rmse_scorer,\n",
    "                                  max_features= a,\n",
    "                                  n_population=1464,\n",
    "                                  crossover_proba=0.5,\n",
    "                                  mutation_proba=0.02,\n",
    "                                  n_generations=55,\n",
    "                                  crossover_independent_proba=0.5,\n",
    "                                  mutation_independent_proba=0.02,\n",
    "                                  tournament_size=5,\n",
    "                                  n_gen_no_change=55,\n",
    "                                  caching=True,\n",
    "                                  n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1 -  Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the dictionaries of scores and the numbers of features selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_scores_DCAA_rf = dict()\n",
    "n_features_mse_DCAA_rf = dict()\n",
    "generations_DCAA_rf = dict()\n",
    "\n",
    "\n",
    "rmse_scores_TCAA_rf = dict()\n",
    "n_features_mse_TCAA_rf = dict()\n",
    "generations_TCAA_rf = dict()\n",
    "\n",
    "for a in max_list:\n",
    "    selector_mse_DCAA_rf[a] = selector_mse_DCAA_rf[a].fit(X, log_y[:,0])\n",
    "    generations_DCAA_rf[a] = np.sqrt(-selector_mse_DCAA_rf[a].generation_scores_)\n",
    "    rmse_scores_DCAA_rf[a] = np.sqrt(-selector_mse_DCAA_rf[a].generation_scores_[10])\n",
    "    n_features_mse_DCAA_rf[a] = selector_mse_DCAA_rf[a].n_features_\n",
    "    \n",
    "    \n",
    "    selector_mse_TCAA_rf[a] = selector_mse_TCAA_rf[a].fit(X,log_y[:,1])\n",
    "    generations_TCAA_rf[a] = np.sqrt(-selector_mse_TCAA_rf[a].generation_scores_)\n",
    "    rmse_scores_TCAA_rf[a] = np.sqrt(-selector_mse_TCAA_rf[a].generation_scores_[10])\n",
    "    n_features_mse_TCAA_rf[a] = selector_mse_TCAA_rf[a].n_features_\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    x_DCAA = np.array(list(n_features_mse_DCAA_rf.values())).astype(float)\n",
    "    y_DCAA = np.array(list(rmse_scores_DCAA_rf.values())).astype(float)\n",
    "    x_TCAA = np.array(list(n_features_mse_TCAA_rf.values())).astype(float)\n",
    "    y_TCAA = np.array(list(rmse_scores_TCAA_rf.values())).astype(float)\n",
    "    plt.scatter(x_DCAA, y_DCAA, color = \"red\")\n",
    "    plt.scatter(x_TCAA, y_TCAA, color = \"blue\")\n",
    "    plt.ylim(0.5,2)\n",
    "    plt.ylabel(\"Cross-validation score (RMSE$_{CV}$)\")\n",
    "    plt.xlabel(\"Number of features selected\")\n",
    "    plt.legend([\"DCAA\", \"TCAA\"])\n",
    "    \n",
    "    plt.savefig(\"../Jupyter/results/figures/RF_\" +str(a) + \"descs_20200516.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#black and white\n",
    "plt.scatter(x_DCAA, y_DCAA, color = \"black\", marker  = \"^\")\n",
    "plt.scatter(x_TCAA, y_TCAA, color = \"black\")\n",
    "plt.ylim(0.5,2)\n",
    "plt.ylabel(\"Cross-validation score (RMSE$_{CV}$)\")\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.legend([\"DCAA\", \"TCAA\"])\n",
    "\n",
    "\n",
    "plt.show()\n",
    "plt.savefig(\"../Jupyter/results/figures/feature selection_B&W\" + \"RF_202005015.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store selector_mse_DCAA_rf\n",
    "%store selector_mse_TCAA_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store rmse_scores_DCAA_rf\n",
    "%store rmse_scores_TCAA_rf\n",
    "\n",
    "%store generations_DCAA_rf\n",
    "%store generations_TCAA_rf\n",
    "\n",
    "%store n_features_mse_DCAA_rf\n",
    "%store n_features_mse_TCAA_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2 - SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rmse_scores_DCAA_svr = dict()\n",
    "n_features_mse_DCAA_svr = dict()\n",
    "generations_DCAA_svr = dict()\n",
    "\n",
    "\n",
    "rmse_scores_TCAA_svr = dict()\n",
    "n_features_mse_TCAA_svr = dict()\n",
    "generations_TCAA_svr = dict()\n",
    "\n",
    "\n",
    "\n",
    "for a in max_list:\n",
    "    selector_mse_DCAA_svr[a] = selector_mse_DCAA_svr[a].fit(X, log_y[:,0])\n",
    "    generations_DCAA_svr[a] = np.sqrt(-selector_mse_DCAA_svr[a].generation_scores_)\n",
    "    rmse_scores_DCAA_svr[a] = np.sqrt(-selector_mse_DCAA_svr[a].generation_scores_[55])\n",
    "    n_features_mse_DCAA_svr[a] = selector_mse_DCAA_svr[a].n_features_\n",
    "    \n",
    "    selector_mse_TCAA_svr[a] = selector_mse_TCAA_svr[a].fit(X, log_y[:,1])\n",
    "    generations_TCAA_svr[a] = np.sqrt(-selector_mse_TCAA_svr[a].generation_scores_)\n",
    "    rmse_scores_TCAA_svr[a] = np.sqrt(-selector_mse_TCAA_svr[a].generation_scores_[55])\n",
    "    n_features_mse_TCAA_svr[a] = selector_mse_TCAA_svr[a].n_features_\n",
    "    \n",
    "    \n",
    "    x_DCAA = np.array(list(n_features_mse_DCAA_svr.values())).astype(float)\n",
    "    y_DCAA = np.array(list(rmse_scores_DCAA_svr.values())).astype(float)\n",
    "    x_TCAA = np.array(list(n_features_mse_TCAA_svr.values())).astype(float)\n",
    "    y_TCAA = np.array(list(rmse_scores_TCAA_svr.values())).astype(float)\n",
    "    plt.scatter(x_DCAA, y_DCAA, color = \"red\")\n",
    "    plt.scatter(x_TCAA, y_TCAA, color = \"blue\")\n",
    "    plt.ylim(0.5,2)\n",
    "    plt.ylabel(\"Cross-validation score (RMSE$_{CV}$)\")\n",
    "    plt.xlabel(\"Number of features selected\")\n",
    "    plt.legend([\"DCAA\", \"TCAA\"])\n",
    "    \n",
    "    plt.savefig(\"../Jupyter/results/figures/SVR_\" +str(a) + \"descs_20200516.pdf\")\n",
    "    plt.show()\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store selector_mse_DCAA_svr\n",
    "%store selector_mse_TCAA_svr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#black and white\n",
    "plt.scatter(x_DCAA, y_DCAA, color = \"black\", marker  = \"^\")\n",
    "plt.scatter(x_TCAA, y_TCAA, color = \"black\")\n",
    "plt.ylim(0.5,2)\n",
    "plt.ylabel(\"Cross-validation score (RMSE$_{CV}$)\")\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.legend([\"DCAA\", \"TCAA\"])\n",
    "\n",
    "\n",
    "plt.show()\n",
    "plt.savefig(\"../Jupyter/results/figures/feature selection_B&W\" + \"SVR_20200516.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generations plots. Show that optimum solutions for both algorithms were found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVR\n",
    "# This plot shows the improvement in score over generations for different values of n_features.\n",
    "# TCAA and DCAA are shown as subplots\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, sharex= True, sharey= True, figsize = (6,4))\n",
    "# plt.ylabel(\"Cross-validation score (Q$^2$)\")\n",
    "# plt.xlabel(\"Number of generations\")\n",
    "\n",
    "\n",
    "for a in max_list:\n",
    "    ax[0].plot(range(1, len(generations_DCAA_svr[a]) + 1), generations_DCAA_svr[a])\n",
    "    ax[1].plot(range(1, len(generations_TCAA_svr[a]) + 1), generations_TCAA_svr[a])\n",
    "    \n",
    "    ax[1].legend(list(n_features_mse_DCAA_svr.values()), loc = \"center left\", bbox_to_anchor = (1,0.5))\n",
    "    \n",
    "\n",
    "    \n",
    "plt.ylim(0.5,2) \n",
    "\n",
    "fig.text(0.5, 0.92, \"Support Vector Regressor\", ha='center')\n",
    "fig.text(0.5, 0.004, \"Number of generations\", ha='center')\n",
    "fig.text(0.04, 0.5, \"Cross-validation score (RMSE$_{CV}$)\", va='center', rotation='vertical')\n",
    "\n",
    "plt.savefig(\"../Jupyter/results/figures/Genetic algorithm_SVR_rmsevsNgen_DCAA&TCAA_20200516.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generations_DCAA_rf[a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RF\n",
    "# This plot shows the improvement in r2 over generations for different values of n_features.\n",
    "# TCAA and DCAA are shown as subplots\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, sharex= True, sharey= True, figsize = (6,4))\n",
    "# plt.ylabel(\"Cross-validation score (Q$^2$)\")\n",
    "# plt.xlabel(\"Number of generations\")\n",
    "\n",
    "\n",
    "for a in max_list:\n",
    "    ax[0].plot(range(1, len(generations_DCAA_rf[a]) + 1), generations_DCAA_rf[a])\n",
    "    ax[1].plot(range(1, len(generations_TCAA_rf[a]) + 1), generations_TCAA_rf[a])\n",
    "    \n",
    "    ax[1].legend(list(n_features_mse_DCAA_rf.values()), loc = \"center left\", bbox_to_anchor = (1,0.5))\n",
    "    \n",
    "plt.ylim(0.5,2) \n",
    "\n",
    "fig.text(0.5, 0.92, \"Random Forest regressor\", ha='center')\n",
    "fig.text(0.5, 0.004, \"Number of generations\", ha='center')\n",
    "fig.text(0.04, 0.5, \"Cross-validation score (RMSE$_{CV}$)\", va='center', rotation='vertical')\n",
    "\n",
    "plt.savefig(\"../Jupyter/results/figures/Genetic algorithm_RF_rmsevsNgen_DCAA&TCAA_20200515.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the dictionaries of scores and the numbers of features selected by GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#These variables allow to have the X_train and X_test filtered with the selected descriptors.\n",
    "#Different subsets will allow different train and test sets (e.g. X_train_DCAA_rf)\n",
    "\n",
    "features = list(df_qsar.columns.values)\n",
    "X_train_df = pd.DataFrame(X_train)\n",
    "X_train_df = X_train_df.rename(columns=dict(zip(X_train_df,features)))\n",
    "\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "X_test_df = X_test_df.rename(columns=dict(zip(X_test_df,features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = pd.DataFrame(X)\n",
    "X_df = X_df.rename(columns=dict(zip(X_df,features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the descriptors selected by GA-RF as best predictors of DCAA\n",
    "\n",
    "support_DCAA_rf = dict()\n",
    "features_list_DCAA_rf = dict()\n",
    "\n",
    "X_DCAA_rf = dict()\n",
    "X_test_DCAA_rf = dict()\n",
    "X_train_DCAA_rf = dict()\n",
    "\n",
    "y_predicted_DCAA_rf = dict()\n",
    "rmse_ext_DCAA_rf = dict()\n",
    "r2_ext_DCAA_rf = dict()\n",
    "\n",
    "\n",
    "for a in max_list:\n",
    "    support_DCAA_rf[a] = selector_mse_DCAA_rf[a].support_\n",
    "    support_DCAA_rf[a] = pd.DataFrame(support_DCAA_rf[a])\n",
    "    support_DCAA_rf[a][\"Features\"] = features\n",
    "    support_DCAA_rf[a].columns = [\"Boolean\", \"Features\"]\n",
    "    support_DCAA_rf[a] = support_DCAA_rf[a][support_DCAA_rf[a][\"Boolean\"] == True]\n",
    "    support_DCAA_rf[a] = support_DCAA_rf[a].drop(columns = \"Boolean\")\n",
    "    features_list_DCAA_rf[a] = support_DCAA_rf[a][\"Features\"].tolist()\n",
    "    \n",
    "    X_DCAA_rf[a] = X_df.filter(features_list_DCAA_rf[a], axis = 1)     \n",
    "    X_DCAA_rf[a] = X_DCAA_rf[a].values\n",
    "    \n",
    "    X_train_DCAA_rf[a] = X_train_df.filter(features_list_DCAA_rf[a], axis = 1)\n",
    "    X_train_DCAA_rf[a] = X_train_DCAA_rf[a].values\n",
    "    \n",
    "    X_test_DCAA_rf[a] = X_test_df.filter(features_list_DCAA_rf[a], axis = 1)\n",
    "    X_test_DCAA_rf[a] = X_test_DCAA_rf[a].values\n",
    "    \n",
    "    \n",
    "    pipe_DCAA_rf.fit(X_train_DCAA_rf[a], y_train[:,0])\n",
    "    y_predicted_DCAA_rf[a] = pipe_DCAA_rf.predict(X_test_DCAA_rf[a])\n",
    "    rmse_ext_DCAA_rf[a] = metrics.mean_squared_error(y_test[:,0], y_predicted_DCAA_rf[a], squared = False)\n",
    "    r2_ext_DCAA_rf[a] = metrics.r2_score(y_test[:,0], y_predicted_DCAA_rf[a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_DCAA_rf[5].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_DCAA_rf[5].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_DCAA_svr[5].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the descriptors selected by GA-RF as best predictors of TCAA\n",
    "\n",
    "support_TCAA_rf = dict()\n",
    "features_list_TCAA_rf = dict()\n",
    "\n",
    "X_TCAA_rf = dict()\n",
    "X_test_TCAA_rf = dict()\n",
    "X_train_TCAA_rf = dict()\n",
    "\n",
    "y_predicted_TCAA_rf = dict()\n",
    "rmse_ext_TCAA_rf = dict()\n",
    "r2_ext_TCAA_rf = dict()\n",
    "\n",
    "\n",
    "for a in max_list:\n",
    "    support_TCAA_rf[a] = selector_mse_TCAA_rf[a].support_\n",
    "    support_TCAA_rf[a] = pd.DataFrame(support_TCAA_rf[a])\n",
    "    support_TCAA_rf[a][\"Features\"] = features\n",
    "    support_TCAA_rf[a].columns = [\"Boolean\", \"Features\"]\n",
    "    support_TCAA_rf[a] = support_TCAA_rf[a][support_TCAA_rf[a][\"Boolean\"] == True]\n",
    "    support_TCAA_rf[a] = support_TCAA_rf[a].drop(columns = \"Boolean\")\n",
    "    features_list_TCAA_rf[a] = support_TCAA_rf[a][\"Features\"].tolist()\n",
    "    \n",
    "    X_TCAA_rf[a] = X_df.filter(features_list_TCAA_rf[a], axis = 1)\n",
    "    X_TCAA_rf[a] = X_TCAA_rf[a].values   \n",
    "    \n",
    "    X_train_TCAA_rf[a] = X_train_df.filter(features_list_TCAA_rf[a], axis = 1)\n",
    "    X_train_TCAA_rf[a] = X_train_TCAA_rf[a].values\n",
    "    \n",
    "    X_test_TCAA_rf[a] = X_test_df.filter(features_list_TCAA_rf[a], axis = 1)\n",
    "    X_test_TCAA_rf[a] = X_test_TCAA_rf[a].values\n",
    "    \n",
    "    pipe_TCAA_rf.fit(X_train_TCAA_rf[a], y_train[:,1])\n",
    "    y_predicted_TCAA_rf[a] = pipe_TCAA_rf.predict(X_test_TCAA_rf[a])\n",
    "    rmse_ext_TCAA_rf[a] = metrics.mean_squared_error(y_test[:,1], y_predicted_TCAA_rf[a], squared = False)\n",
    "    r2_ext_TCAA_rf[a] = metrics.r2_score(y_test[:,1], y_predicted_TCAA_rf[a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r2_ext_DCAA_rf)\n",
    "print(r2_ext_TCAA_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features_list_DCAA_rf)\n",
    "print(features_list_TCAA_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the dictionaries of scores and the numbers of features selected by SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the descriptors selected by GA-SVR as best predictors of DCAA\n",
    "\n",
    "support_DCAA_svr = dict()\n",
    "features_list_DCAA_svr = dict()\n",
    "\n",
    "X_DCAA_svr = dict()\n",
    "X_test_DCAA_svr = dict()\n",
    "X_train_DCAA_svr = dict()\n",
    "\n",
    "y_predicted_DCAA_svr = dict()\n",
    "rmse_ext_DCAA_svr = dict()\n",
    "r2_ext_DCAA_svr = dict()\n",
    "\n",
    "\n",
    "for a in max_list:\n",
    "    support_DCAA_svr[a] = selector_mse_DCAA_svr[a].support_\n",
    "    support_DCAA_svr[a] = pd.DataFrame(support_DCAA_svr[a])\n",
    "    support_DCAA_svr[a][\"Features\"] = features\n",
    "    support_DCAA_svr[a].columns = [\"Boolean\", \"Features\"]\n",
    "    support_DCAA_svr[a] = support_DCAA_svr[a][support_DCAA_svr[a][\"Boolean\"] == True]\n",
    "    support_DCAA_svr[a] = support_DCAA_svr[a].drop(columns = \"Boolean\")\n",
    "    features_list_DCAA_svr[a] = support_DCAA_svr[a][\"Features\"].tolist()\n",
    "    \n",
    "    X_DCAA_svr[a] = X_df.filter(features_list_DCAA_svr[a], axis = 1)\n",
    "    X_DCAA_svr[a] = X_DCAA_svr[a].values\n",
    "    \n",
    "    X_train_DCAA_svr[a] = X_train_df.filter(features_list_DCAA_svr[a], axis = 1)\n",
    "    X_train_DCAA_svr[a] = X_train_DCAA_svr[a].values\n",
    "    \n",
    "    X_test_DCAA_svr[a] = X_test_df.filter(features_list_DCAA_svr[a], axis = 1)\n",
    "    X_test_DCAA_svr[a] = X_test_DCAA_svr[a].values\n",
    "    \n",
    "    \n",
    "    pipe_DCAA_svr.fit(X_train_DCAA_svr[a], y_train[:,0])\n",
    "    y_predicted_DCAA_svr[a] = pipe_DCAA_svr.predict(X_test_DCAA_svr[a])\n",
    "    rmse_ext_DCAA_svr[a] = metrics.mean_squared_error(y_test[:,0], y_predicted_DCAA_svr[a], squared = False)\n",
    "    r2_ext_DCAA_svr[a] = metrics.r2_score(y_test[:,0], y_predicted_DCAA_svr[a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the descriptors selected by GA-SVR as best predictors of TCAA\n",
    "\n",
    "support_TCAA_svr = dict()\n",
    "features_list_TCAA_svr = dict()\n",
    "\n",
    "X_TCAA_svr = dict()\n",
    "X_test_TCAA_svr = dict()\n",
    "X_train_TCAA_svr = dict()\n",
    "\n",
    "y_predicted_TCAA_svr = dict()\n",
    "rmse_ext_TCAA_svr = dict()\n",
    "r2_ext_TCAA_svr = dict()\n",
    "\n",
    "\n",
    "for a in max_list:\n",
    "    support_TCAA_svr[a] = selector_mse_TCAA_svr[a].support_\n",
    "    support_TCAA_svr[a] = pd.DataFrame(support_TCAA_svr[a])\n",
    "    support_TCAA_svr[a][\"Features\"] = features\n",
    "    support_TCAA_svr[a].columns = [\"Boolean\", \"Features\"]\n",
    "    support_TCAA_svr[a] = support_TCAA_svr[a][support_TCAA_svr[a][\"Boolean\"] == True]\n",
    "    support_TCAA_svr[a] = support_TCAA_svr[a].drop(columns = \"Boolean\")\n",
    "    features_list_TCAA_svr[a] = support_TCAA_svr[a][\"Features\"].tolist()\n",
    "    \n",
    "    X_TCAA_svr[a] = X_df.filter(features_list_TCAA_svr[a], axis = 1)\n",
    "    X_TCAA_svr[a] = X_TCAA_svr[a].values\n",
    "    \n",
    "    X_train_TCAA_svr[a] = X_train_df.filter(features_list_TCAA_svr[a], axis = 1)\n",
    "    X_train_TCAA_svr[a] = X_train_TCAA_svr[a].values\n",
    "    \n",
    "    X_test_TCAA_svr[a] = X_test_df.filter(features_list_TCAA_svr[a], axis = 1)\n",
    "    X_test_TCAA_svr[a] = X_test_TCAA_svr[a].values\n",
    "    \n",
    "    \n",
    "    pipe_TCAA_svr.fit(X_train_TCAA_svr[a], y_train[:,1])\n",
    "    y_predicted_TCAA_svr[a] = pipe_TCAA_svr.predict(X_test_TCAA_svr[a])\n",
    "    rmse_ext_TCAA_svr[a] = metrics.mean_squared_error(y_test[:,1], y_predicted_TCAA_svr[a], squared = False)\n",
    "    r2_ext_TCAA_svr[a] = metrics.r2_score(y_test[:,1], y_predicted_TCAA_svr[a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r2_ext_DCAA_svr)\n",
    "print(r2_ext_TCAA_svr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features_list_DCAA_svr)\n",
    "print(features_list_TCAA_svr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics for the linear models - Evaluate subsets of descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of selectors \n",
    "\n",
    "\n",
    "DCAA_regressors = {\"RF_opt\" : RandomForestRegressor(random_state = 17,\n",
    "                                    n_estimators = 300,\n",
    "                                    max_features = \"auto\",\n",
    "                                    min_samples_split = 0.03,\n",
    "                                    min_samples_leaf = 0.01,\n",
    "                                    max_depth = 10,\n",
    "                                    max_leaf_nodes = None,\n",
    "                                    n_jobs = -1),\n",
    "              \"SVR_{rbf}_opt\" : SVR(C=6,\n",
    "                                    epsilon=0.0003,\n",
    "                                    gamma=0.003,\n",
    "                                    kernel='rbf',\n",
    "                                    max_iter=-1,\n",
    "                                    shrinking=True,\n",
    "                                    tol=0.001,\n",
    "                                    verbose=False),\n",
    "                   \"SVR_{linear}\" : svm.SVR(kernel = \"linear\"),\n",
    "                   \"MLP\" : MLPRegressor(solver = \"lbfgs\", max_iter = 400, random_state = 17),\n",
    "                   \"MLR\" : linear_model.LinearRegression()}\n",
    "\n",
    "TCAA_regressors = {\"RF_opt\" : RandomForestRegressor(random_state = 17,\n",
    "                                    n_estimators = 100,\n",
    "                                    max_features = \"auto\",\n",
    "                                    min_samples_split = 2,\n",
    "                                    min_samples_leaf = 1,\n",
    "                                    max_depth = 30,\n",
    "                                    max_leaf_nodes = None),\n",
    "              \"SVR_{rbf}_opt\" : SVR(C=3,\n",
    "                                    epsilon=0.3,\n",
    "                                    gamma=0.001,\n",
    "                                    kernel='rbf',\n",
    "                                    max_iter=-1,\n",
    "                                    shrinking=True,\n",
    "                                    tol=0.001,\n",
    "                                    verbose=False),\n",
    "                   \"SVR_{linear}\" : svm.SVR(kernel = \"linear\"),\n",
    "                   \"MLP\" : MLPRegressor(solver = \"lbfgs\", max_iter = 400, random_state = 17),\n",
    "                   \"MLR\" : linear_model.LinearRegression()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate using the input provided by RF\n",
    "# get scores for DCAA\n",
    "\n",
    "y_pred_DCAA_rf = dict()\n",
    "\n",
    "r2_DCAA_cv = dict()\n",
    "rmse_DCAA_cv = dict()\n",
    "r2_DCAA_ext = dict ()\n",
    "rmse_DCAA_ext = dict()\n",
    "\n",
    "scores_DCAA = dict()\n",
    "\n",
    "reg_list_DCAA = DCAA_regressors.keys()\n",
    "\n",
    "for a in reg_list_DCAA:\n",
    "    for b in max_list:\n",
    "        DCAA_regressors[a] = DCAA_regressors[a].fit(X_train_DCAA_rf[b], y_train[:,0])\n",
    "        y_pred_DCAA_rf[b] = DCAA_regressors[a].predict(X_test_DCAA_rf[b])\n",
    "    \n",
    "#         r2_TCAA_cv[a] = model_selection.cross_validate(TCAA_regressors[a], X_train_scaled,y_train[:,1], scoring = \"r2\", cv =5 )\n",
    "#         r2_TCAA_cv[a] = mean(r2_TCAA_cv[a][\"test_score\"])\n",
    "#         rmse_TCAA_cv[a] = model_selection.cross_validate(TCAA_regressors[a], X_train_scaled,y_train[:,1], scoring = \"neg_root_mean_squared_error\", cv =5 )\n",
    "#         rmse_TCAA_cv[a] = -mean(rmse_TCAA_cv[a][\"test_score\"])\n",
    "        r2_DCAA_ext[b] = DCAA_regressors[a].score(X_test_DCAA_rf[b], y_test[:,0])\n",
    "#         rmse_TCAA_ext[a] = sqrt(mean_squared_error(y_test[:,1], (y_pred_TCAA[a])))\n",
    "        \n",
    "#         print(\"n_descs: {:.5f}, R2: {:.5f}\".format(max_list[b].keys, r2_DCAA_ext[b]))\n",
    "        print(str(a) + \"_\" + str(b))\n",
    "        print(r2_DCAA_ext[b])\n",
    "        #scores = dict(zip(reg_list_DCAA[a], r2_DCAA_ext[b]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate using the input provided by RF\n",
    "# get scores for TCAA\n",
    "\n",
    "y_pred_TCAA_rf = dict()\n",
    "\n",
    "r2_TCAA_cv = dict()\n",
    "rmse_TCAA_cv = dict()\n",
    "r2_TCAA_ext = dict ()\n",
    "rmse_TCAA_ext = dict()\n",
    "\n",
    "scores_TCAA = dict()\n",
    "\n",
    "reg_list_TCAA = TCAA_regressors.keys()\n",
    "\n",
    "for a in reg_list_TCAA:\n",
    "    for b in max_list:\n",
    "        TCAA_regressors[a] = TCAA_regressors[a].fit(X_train_TCAA_rf[b], y_train[:,1])\n",
    "        y_pred_TCAA_rf[b] = TCAA_regressors[a].predict(X_test_TCAA_rf[b])\n",
    "    \n",
    "#         r2_TCAA_cv[a] = model_selection.cross_validate(TCAA_regressors[a], X_train_scaled,y_train[:,1], scoring = \"r2\", cv =5 )\n",
    "#         r2_TCAA_cv[a] = mean(r2_TCAA_cv[a][\"test_score\"])\n",
    "#         rmse_TCAA_cv[a] = model_selection.cross_validate(TCAA_regressors[a], X_train_scaled,y_train[:,1], scoring = \"neg_root_mean_squared_error\", cv =5 )\n",
    "#         rmse_TCAA_cv[a] = -mean(rmse_TCAA_cv[a][\"test_score\"])\n",
    "        r2_TCAA_ext[b] = TCAA_regressors[a].score(X_test_TCAA_rf[b], y_test[:,1])\n",
    "#         rmse_TCAA_ext[a] = sqrt(mean_squared_error(y_test[:,1], (y_pred_TCAA[a])))\n",
    "        \n",
    "#         print(\"n_descs: {:.5f}, R2: {:.5f}\".format(max_list[b].keys, r2_DCAA_ext[b]))\n",
    "        print(str(a) + \"_\" + str(b))\n",
    "        print(r2_TCAA_ext[b])\n",
    "        #scores = dict(zip(reg_list_DCAA[a], r2_DCAA_ext[b]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate using GA-SVR subset as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate using the input provided by SVR\n",
    "# get scores for DCAA\n",
    "\n",
    "y_pred_DCAA_svr = dict()\n",
    "\n",
    "r2_DCAA_cv = dict()\n",
    "rmse_DCAA_cv = dict()\n",
    "r2_DCAA_ext = dict ()\n",
    "rmse_DCAA_ext = dict()\n",
    "\n",
    "scores_DCAA = dict()\n",
    "\n",
    "reg_list_DCAA = DCAA_regressors.keys()\n",
    "\n",
    "for a in reg_list_DCAA:\n",
    "    for b in max_list:\n",
    "        DCAA_regressors[a] = DCAA_regressors[a].fit(X_train_DCAA_svr[b], y_train[:,0])\n",
    "        y_pred_DCAA_svr[b] = DCAA_regressors[a].predict(X_test_DCAA_svr[b])\n",
    "    \n",
    "#         r2_TCAA_cv[a] = model_selection.cross_validate(TCAA_regressors[a], X_train_scaled,y_train[:,1], scoring = \"r2\", cv =5 )\n",
    "#         r2_TCAA_cv[a] = mean(r2_TCAA_cv[a][\"test_score\"])\n",
    "#         rmse_TCAA_cv[a] = model_selection.cross_validate(TCAA_regressors[a], X_train_scaled,y_train[:,1], scoring = \"neg_root_mean_squared_error\", cv =5 )\n",
    "#         rmse_TCAA_cv[a] = -mean(rmse_TCAA_cv[a][\"test_score\"])\n",
    "        r2_DCAA_ext[b] = DCAA_regressors[a].score(X_test_DCAA_svr[b], y_test[:,0])\n",
    "#         rmse_TCAA_ext[a] = sqrt(mean_squared_error(y_test[:,1], (y_pred_TCAA[a])))\n",
    "        \n",
    "#         print(\"n_descs: {:.5f}, R2: {:.5f}\".format(max_list[b].keys, r2_DCAA_ext[b]))\n",
    "        print(str(a) + \"_\" + str(b))\n",
    "        print(r2_DCAA_ext[b])\n",
    "        #scores = dict(zip(reg_list_DCAA[a], r2_DCAA_ext[b]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate using the input provided by SVR\n",
    "# get scores for TCAA\n",
    "\n",
    "y_pred_TCAA_svr = dict()\n",
    "\n",
    "r2_TCAA_cv = dict()\n",
    "rmse_TCAA_cv = dict()\n",
    "r2_TCAA_ext = dict ()\n",
    "rmse_TCAA_ext = dict()\n",
    "\n",
    "scores_TCAA = dict()\n",
    "\n",
    "reg_list_TCAA = TCAA_regressors.keys()\n",
    "\n",
    "for a in reg_list_TCAA:\n",
    "    for b in max_list:\n",
    "        TCAA_regressors[a] = TCAA_regressors[a].fit(X_train_TCAA_svr[b], y_train[:,1])\n",
    "        y_pred_TCAA_svr[b] = TCAA_regressors[a].predict(X_test_TCAA_svr[b])\n",
    "    \n",
    "#         r2_TCAA_cv[a] = model_selection.cross_validate(TCAA_regressors[a], X_train_scaled,y_train[:,1], scoring = \"r2\", cv =5 )\n",
    "#         r2_TCAA_cv[a] = mean(r2_TCAA_cv[a][\"test_score\"])\n",
    "#         rmse_TCAA_cv[a] = model_selection.cross_validate(TCAA_regressors[a], X_train_scaled,y_train[:,1], scoring = \"neg_root_mean_squared_error\", cv =5 )\n",
    "#         rmse_TCAA_cv[a] = -mean(rmse_TCAA_cv[a][\"test_score\"])\n",
    "        r2_TCAA_ext[b] = TCAA_regressors[a].score(X_test_TCAA_svr[b], y_test[:,1])\n",
    "#         rmse_TCAA_ext[a] = sqrt(mean_squared_error(y_test[:,1], (y_pred_TCAA[a])))\n",
    "        \n",
    "#         print(\"n_descs: {:.5f}, R2: {:.5f}\".format(max_list[b].keys, r2_DCAA_ext[b]))\n",
    "        print(str(a) + \"_\" + str(b))\n",
    "        print(r2_TCAA_ext[b])\n",
    "        #scores = dict(zip(reg_list_DCAA[a], r2_DCAA_ext[b]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test LOO-CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_DCAA_rf[20].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluate LOO-Q2 in all regressors using the input provided by RF\n",
    "\n",
    "\n",
    "reg_list_DCAA = DCAA_regressors.keys()\n",
    "\n",
    "\n",
    "# calculate the leave one out cross validation for DCAA\n",
    "\n",
    "\n",
    "loo_q2_DCAA = dict()\n",
    "loo_rmse_DCAA = dict ()\n",
    "\n",
    "y_tests_nested_dict = dict()\n",
    "y_preds_nested_dict = dict()\n",
    "\n",
    "y_tests_dict = dict()\n",
    "y_preds_dict = dict()\n",
    "\n",
    "\n",
    "reg_list_DCAA = DCAA_regressors.keys()\n",
    "\n",
    "yr = log_y[:,0] #y is the same for every regressor, just remember to differentiate TCAA and DCAA. \n",
    "\n",
    "for a in reg_list_DCAA:\n",
    "    for b in max_list:\n",
    "        Xr = X_DCAA_rf[b] #the key is to define a different Xr per subset of descs X_train_DCAA_rf[b] \n",
    "        loo = LeaveOneOut()\n",
    "        ytests = []\n",
    "        ypreds = []\n",
    "        for train_idx, test_idx in loo.split(Xr):\n",
    "            X_train, X_test = Xr[train_idx], Xr[test_idx] #requires arrays\n",
    "            y_train, y_test = yr[train_idx], yr[test_idx]\n",
    "    \n",
    "            #models\n",
    "            DCAA_regressors[a].fit(X = X_train, y = y_train) \n",
    "            y_pred = DCAA_regressors[a].predict(X_test)\n",
    "        \n",
    "        # there is only one y-test and y-pred per iteration over the loo.split, \n",
    "        # so to get a proper graph, we append them to respective lists.\n",
    "        \n",
    "            ytests += list(y_test)\n",
    "            ypreds += list(y_pred)\n",
    "        \n",
    "        y_tests_dict[b] = ytests\n",
    "        y_preds_dict[b] = ypreds\n",
    "        \n",
    "        \n",
    "        loo_q2_DCAA[b] = metrics.r2_score(ytests, ypreds)\n",
    "        loo_rmse_DCAA[b] = metrics.mean_squared_error(ytests, ypreds, squared = False)\n",
    "        \n",
    "        print(str(a) + \"_\" + str(b))\n",
    "        print(\"Leave One Out Cross Validation\" + str(a))\n",
    "        print(\"LOO $Q^2$: {:.5f}, MSE: {:.5f}\".format(loo_q2_DCAA[b], loo_rmse_DCAA[b]))\n",
    "    y_tests_nested_dict[a] = {str(b): y_tests_dict[b]}\n",
    "    y_preds_nested_dict[a] = {str(b): y_preds_dict[b]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluate LOO-Q2 in all regressors using the input provided by RF\n",
    "\n",
    "\n",
    "reg_list_TCAA = TCAA_regressors.keys()\n",
    "\n",
    "\n",
    "# calculate the leave one out cross validation for TCAA\n",
    "\n",
    "\n",
    "loo_q2_TCAA = dict()\n",
    "loo_rmse_TCAA = dict ()\n",
    "\n",
    "y_tests_nested_dict_TCAA = dict()\n",
    "y_preds_nested_dict_TCAA = dict()\n",
    "\n",
    "y_tests_dict_TCAA = dict()\n",
    "y_preds_dict_TCAA = dict()\n",
    "\n",
    "\n",
    "\n",
    "yr = log_y[:,1] #y is the same for every regressor, just remember to differentiate TCAA and DCAA. \n",
    "\n",
    "for a in reg_list_TCAA:\n",
    "    for b in max_list:\n",
    "        Xr = X_TCAA_rf[b] #the key is to define a different Xr per subset of descs X_train_DCAA_rf[b] \n",
    "        loo = LeaveOneOut()\n",
    "        ytests = []\n",
    "        ypreds = []\n",
    "        for train_idx, test_idx in loo.split(Xr):\n",
    "            X_train, X_test = Xr[train_idx], Xr[test_idx] #requires arrays\n",
    "            y_train, y_test = yr[train_idx], yr[test_idx]\n",
    "    \n",
    "            #models\n",
    "            TCAA_regressors[a].fit(X = X_train, y = y_train) \n",
    "            y_pred = TCAA_regressors[a].predict(X_test)\n",
    "        \n",
    "        # there is only one y-test and y-pred per iteration over the loo.split, \n",
    "        # so to get a proper graph, we append them to respective lists.\n",
    "        \n",
    "            ytests += list(y_test)\n",
    "            ypreds += list(y_pred)\n",
    "        \n",
    "        y_tests_dict_TCAA[b] = ytests\n",
    "        y_preds_dict_TCAA[b] = ypreds\n",
    "        \n",
    "        \n",
    "        loo_q2_TCAA[b] = metrics.r2_score(ytests, ypreds)\n",
    "        loo_rmse_TCAA[b] = metrics.mean_squared_error(ytests, ypreds, squared = False)\n",
    "        \n",
    "        print(str(a) + \"_\" + str(b))\n",
    "        print(\"Leave One Out Cross Validation\" + str(a))\n",
    "        print(\"LOO $Q^2$: {:.5f}, MSE: {:.5f}\".format(loo_q2_TCAA[b], loo_rmse_TCAA[b]))\n",
    "    y_tests_nested_dict_TCAA[a] = {str(b): y_tests_dict_TCAA[b]}\n",
    "    y_preds_nested_dict_TCAA[a] = {str(b): y_preds_dict_TCAA[b]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input of SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate LOO-Q2 in all regressors using the input provided by RF\n",
    "\n",
    "\n",
    "reg_list_TCAA = TCAA_regressors.keys()\n",
    "\n",
    "\n",
    "# calculate the leave one out cross validation for TCAA\n",
    "\n",
    "\n",
    "loo_q2_TCAA = dict()\n",
    "loo_rmse_TCAA = dict ()\n",
    "\n",
    "y_tests_nested_dict_TCAA = dict()\n",
    "y_preds_nested_dict_TCAA = dict()\n",
    "\n",
    "y_tests_dict_TCAA = dict()\n",
    "y_preds_dict_TCAA = dict()\n",
    "\n",
    "\n",
    "\n",
    "yr = log_y[:,1] #y is the same for every regressor, just remember to differentiate TCAA and DCAA. \n",
    "\n",
    "for a in reg_list_TCAA:\n",
    "    for b in max_list:\n",
    "        Xr = X_TCAA_svr[b] #the key is to define a different Xr per subset of descs X_train_DCAA_rf[b] \n",
    "        loo = LeaveOneOut()\n",
    "        ytests = []\n",
    "        ypreds = []\n",
    "        for train_idx, test_idx in loo.split(Xr):\n",
    "            X_train, X_test = Xr[train_idx], Xr[test_idx] #requires arrays\n",
    "            y_train, y_test = yr[train_idx], yr[test_idx]\n",
    "    \n",
    "            #models\n",
    "            TCAA_regressors[a].fit(X = X_train, y = y_train) \n",
    "            y_pred = TCAA_regressors[a].predict(X_test)\n",
    "        \n",
    "        # there is only one y-test and y-pred per iteration over the loo.split, \n",
    "        # so to get a proper graph, we append them to respective lists.\n",
    "        \n",
    "            ytests += list(y_test)\n",
    "            ypreds += list(y_pred)\n",
    "        \n",
    "        y_tests_dict_TCAA[b] = ytests\n",
    "        y_preds_dict_TCAA[b] = ypreds\n",
    "        \n",
    "        \n",
    "        loo_q2_TCAA[b] = metrics.r2_score(ytests, ypreds)\n",
    "        loo_rmse_TCAA[b] = metrics.mean_squared_error(ytests, ypreds, squared = False)\n",
    "        \n",
    "        print(str(a) + \"_\" + str(b))\n",
    "        print(\"Leave One Out Cross Validation\" + str(a))\n",
    "        print(\"LOO $Q^2$: {:.5f}, MSE: {:.5f}\".format(loo_q2_TCAA[b], loo_rmse_TCAA[b]))\n",
    "    y_tests_nested_dict_TCAA[a] = {str(b): y_tests_dict_TCAA[b]}\n",
    "    y_preds_nested_dict_TCAA[a] = {str(b): y_preds_dict_TCAA[b]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluate LOO-Q2 in all regressors using the input provided by SVR\n",
    "\n",
    "\n",
    "reg_list_DCAA = DCAA_regressors.keys()\n",
    "\n",
    "\n",
    "# calculate the leave one out cross validation for DCAA\n",
    "\n",
    "\n",
    "loo_q2_DCAA = dict()\n",
    "loo_rmse_DCAA = dict ()\n",
    "\n",
    "y_tests_nested_dict = dict()\n",
    "y_preds_nested_dict = dict()\n",
    "\n",
    "y_tests_dict = dict()\n",
    "y_preds_dict = dict()\n",
    "\n",
    "\n",
    "reg_list_DCAA = DCAA_regressors.keys()\n",
    "\n",
    "yr = log_y[:,0] #y is the same for every regressor, just remember to differentiate TCAA and DCAA. \n",
    "\n",
    "for a in reg_list_DCAA:\n",
    "    for b in max_list:\n",
    "        Xr = X_DCAA_svr[b] #the key is to define a different Xr per subset of descs X_train_DCAA_rf[b] \n",
    "        loo = LeaveOneOut()\n",
    "        ytests = []\n",
    "        ypreds = []\n",
    "        for train_idx, test_idx in loo.split(Xr):\n",
    "            X_train, X_test = Xr[train_idx], Xr[test_idx] #requires arrays\n",
    "            y_train, y_test = yr[train_idx], yr[test_idx]\n",
    "    \n",
    "            #models\n",
    "            DCAA_regressors[a].fit(X = X_train, y = y_train) \n",
    "            y_pred = DCAA_regressors[a].predict(X_test)\n",
    "        \n",
    "        # there is only one y-test and y-pred per iteration over the loo.split, \n",
    "        # so to get a proper graph, we append them to respective lists.\n",
    "        \n",
    "            ytests += list(y_test)\n",
    "            ypreds += list(y_pred)\n",
    "        \n",
    "        y_tests_dict[b] = ytests\n",
    "        y_preds_dict[b] = ypreds\n",
    "        \n",
    "        \n",
    "        loo_q2_DCAA[b] = metrics.r2_score(ytests, ypreds)\n",
    "        loo_rmse_DCAA[b] = metrics.mean_squared_error(ytests, ypreds, squared = False)\n",
    "        \n",
    "        print(str(a) + \"_\" + str(b))\n",
    "        print(\"Leave One Out Cross Validation\" + str(a))\n",
    "        print(\"LOO $Q^2$: {:.5f}, MSE: {:.5f}\".format(loo_q2_DCAA[b], loo_rmse_DCAA[b]))\n",
    "    y_tests_nested_dict[a] = {str(b): y_tests_dict[b]}\n",
    "    y_preds_nested_dict[a] = {str(b): y_preds_dict[b]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data of features selected as tables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "support_ga_DCAA = selector_mse_DCAA_rf[10].support_\n",
    "support_ga_TCAA = selector_mse_TCAA_rf[10].support_\n",
    "\n",
    "df_support_ga_DCAA = pd.DataFrame(support_ga_DCAA)\n",
    "df_support_ga_TCAA = pd.DataFrame(support_ga_TCAA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get a list of the names of all features in order to extract the name of the selected descs from df_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list first column of qsar_transposed as \"features\"  to get the names\n",
    "features = list(df_qsar.columns.values)\n",
    "len(features)\n",
    "# join df_qsar_transposed  and df_support\n",
    "df_support_ga_DCAA[\"Features\"] = features\n",
    "df_support_ga_DCAA.columns = [\"Boolean\", \"Features\"]\n",
    "# extract only true values\n",
    "df_support_ga_DCAA_true = df_support_ga_DCAA[df_support_ga_DCAA[\"Boolean\"] == True]\n",
    "#drop the \"Boolean\" and convert to Latex including feature number\n",
    "df_support_ga_DCAA_true_only = df_support_ga_DCAA_true.drop(columns = \"Boolean\")\n",
    "print(df_support_ga_DCAA_true_only.to_latex(index=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list first column of qsar_transposed as \"features\"  to get the names\n",
    "features = list(df_qsar.columns.values)\n",
    "len(features)\n",
    "# join df_qsar_transposed  and df_support\n",
    "df_support_ga_TCAA[\"Features\"] = features\n",
    "df_support_ga_TCAA.columns = [\"Boolean\", \"Features\"]\n",
    "# extract only true values\n",
    "df_support_ga_TCAA_true = df_support_ga_TCAA[df_support_ga_TCAA[\"Boolean\"] == True]\n",
    "#drop the \"Boolean\" and convert to Latex including feature number\n",
    "df_support_ga_TCAA_true_only = df_support_ga_TCAA_true.drop(columns = \"Boolean\")\n",
    "print(df_support_ga_TCAA_true_only.to_latex(index=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list first column of qsar_transposed as \"features\"  to get the names\n",
    "features = list(df_qsar.columns.values)\n",
    "len(features)\n",
    "# join df_qsar_transposed  and df_support\n",
    "df_support_ga[\"Features\"] = features\n",
    "df_support_ga.columns = [\"Boolean\", \"Features\"]\n",
    "# extract only true values\n",
    "df_support_ga_true = df_support_ga[df_support_ga[\"Boolean\"] == True]\n",
    "#drop the \"Boolean\" and convert to Latex including feature number\n",
    "df_support_ga_true_only = df_support_ga_true.drop(columns = \"Boolean\")\n",
    "print(df_support_ga_true_only.to_latex(index=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{array}{cc}\n",
    "\\hline Feature\\:number & Name  \\\\\\hline\n",
    "103 &         ATS8p \\\\\n",
    "114 &       AATS1dv \\\\\n",
    "131 &        AATS2v \\\\\n",
    "152 &        AATS3i \\\\\n",
    "190 &        ATSC1m \\\\\n",
    "208 &       ATSC1se \\\\\n",
    "209 &       ATSC2se \\\\\n",
    "341 &        GATS1m \\\\\n",
    "369 &       nBondsA \\\\\n",
    "378 &         C2SP2 \\\\\n",
    "386 &        Xch-3d \\\\\n",
    "404 &        Xpc-4d \\\\\n",
    "413 &         Xp-4d \\\\\n",
    "460 &         NaasC \\\\\n",
    "508 &          NdSe \\\\\n",
    "535 &        SsssCH \\\\\n",
    "613 &          TIC0 \\\\\n",
    "634 &          CIC3 \\\\\n",
    "653 &  FilterItLogS \\\\\n",
    "693 &   EState\\_VSA5 \\\\\n",
    "723 &         piPC6 \\\\\n",
    "731 &         nRing \\\\\n",
    "782 &       n5ARing \\\\\n",
    "888 &          JGI4 \\\\\n",
    "926 &       Zagreb1 \\\\\n",
    "\\end{array}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting descriptors using RFECV-RF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define estimator( regression model). In case it is necessary for the wrapping method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PipelineRFE(Pipeline):\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        super(PipelineRFE, self).fit(X, y, **fit_params)\n",
    "        self.feature_importances_ = self.steps[-1][-1].feature_importances_\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = PipelineRFE(\n",
    "    [\n",
    "        ('std_scaler', StandardScaler()),\n",
    "        (\"RF\", RandomForestRegressor(random_state = 17))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define selector (wrapping method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = RFECV(pipe, step = 1, cv = 5, scoring=rmse_scorer, verbose = True, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector_RFECV_DCAA = selector.fit(X,log_y[:,0])     #currently y = DCAAFP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector_RFECV_TCAA = selector.fit(X,log_y[:,1])     #currently y = TCAAFP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DCAA_features = selector_RFECV_DCAA.n_features_\n",
    "print (DCAA_features)\n",
    "TCAA_features = selector_RFECV_TCAA.n_features_\n",
    "print (TCAA_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the number of features vs score graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_grid_rmse_DCAA = np.sqrt(-selector_RFECV_DCAA.grid_scores_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_grid_rmse_TCAA = np.sqrt(-selector_RFECV_TCAA.grid_scores_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DCAA plot\n",
    "\n",
    "# Plot number of features VS. cross-validation scores              #square root\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score \")\n",
    "plt.plot(range(1, len(cv_grid_rmse_DCAA) + 1), cv_grid_rmse_DCAA)\n",
    "\n",
    "plt.savefig(\"../Jupyter/results/figures/RFECV_RF_rmsevsNgen_DCAA_20200516.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TCAA plot\n",
    "\n",
    "# Plot number of features VS. cross-validation scores              #square root\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score \")\n",
    "plt.plot(range(1, len(cv_grid_rmse_TCAA) + 1), cv_grid_rmse_TCAA)\n",
    "\n",
    "plt.savefig(\"../Jupyter/results/figures/RFECV_RF_rmsevsNgen_TCAA_20200516.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the features selected by the RFECV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "support_rfecv_DCAA = selector_RFECV_DCAA.support_\n",
    "support_rfecv_TCAA = selector_RFECV_TCAA.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_support_rfecv = pd.DataFrame(support_rfecv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get a list of the names of all features in order to extract the name of the selected descs from df_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list first column of qsar_transposed as \"features\"  to get the names\n",
    "features = list(df_qsar.columns.values)\n",
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join df_qsar_transposed  and df_support\n",
    "df_support_rfecv[\"Features\"] = features                          #include features\n",
    "df_support_rfecv.columns = [\"Boolean\", \"Features\"]               # rename column as Boolean\n",
    "df_support_rfecv_true = df_support_rfecv[df_support_rfecv[\"Boolean\"] == True]    # extract only true values\n",
    "df_support_rfecv_true                           #show head and shape of the \"True features\" table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the simplified model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the list of features (features_rfecv or features_ga) and use it to filter and get the simplified input\n",
    "#df_qsar_rfecv or df_qsar_rfecv\n",
    "#this new data frame can be used as input in other notebooks if stored with an appropiate name\n",
    "#it can be used to test all the preliminary models by creating a copy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfecv_features_list = df_support_rfecv_true[\"Features\"].tolist() \n",
    "ga_features_list = df_support_ga_true[\"Features\"].tolist() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_qsar_new contans only the descriptors selected by RFECV\n",
    "df_qsar_rfecv = df_qsar.filter(rfecv_features_list, axis = 1)\n",
    "df_qsar_ga = df_qsar.filter(ga_features_list, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qsar_ga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #df_qsar_new contans only the descriptors selected by RFECV\n",
    "# df_qsar_rfecv = df_qsar.filter([\"ATS8m\", \"ATSC1are\", \"ATSC2i\", \"ZMIC1\", \"ZMIC2\", \"SlogP_VSA10\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qsar_rfecv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store df_qsar_ga\n",
    "%store df_qsar_rfecv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
