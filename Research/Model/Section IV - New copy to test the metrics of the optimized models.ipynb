{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from rdkit import Chem\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from statistics import mean\n",
    "\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    " #These are stored after running the \"Data preprocessing\" notebook\n",
    "\n",
    "%store -r X_train         \n",
    "%store  -r X_test\n",
    "\n",
    "%store -r y_train\n",
    "%store -r  y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(194, 929)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling and Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale x_train\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "\n",
    "scaler = StandardScaler().fit(X_test)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionary of regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a dictionary regressors() were all regressors are stored\n",
    "\n",
    "DCAA_regressors = {\"RF\" : RandomForestRegressor(random_state = 17,\n",
    "                                    n_estimators = 100,\n",
    "                                    max_features = 100,\n",
    "                                    min_samples_split = 0.1,\n",
    "                                    min_samples_leaf = 0.03,\n",
    "                                    max_depth = 10,\n",
    "                                    max_leaf_nodes = 300),\n",
    "              \"SVR_{rbf}\" : svm.SVR(C = 30,\n",
    "                                    epsilon = 0.3,\n",
    "                                    gamma = 0.0006),\n",
    "              \"SVR_{linear}\" : svm.SVR(kernel = \"linear\"),\n",
    "                  \"MLP\" : MLPRegressor(solver = \"lbfgs\",max_iter = 400, random_state = 17),\n",
    "                  \"MLR\" : linear_model.LinearRegression()}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a dictionary regressors() were all regressors are stored\n",
    "\n",
    "TCAA_regressors = {\"RF\" : RandomForestRegressor(max_depth = 10,\n",
    "                                         max_features = 'auto',\n",
    "                                         max_leaf_nodes = 10,\n",
    "                                         min_samples_leaf= 0.03,\n",
    "                                         min_samples_split = 0.1,\n",
    "                                         n_estimators = 1000),\n",
    "              \"SVR_{rbf}\" : svm.SVR(C = 10,\n",
    "                                    epsilon = 0.1,\n",
    "                                    gamma = 0.001),\n",
    "              \"SVR_{linear}\" : svm.SVR(kernel = \"linear\"),\n",
    "                  \"MLP\" : MLPRegressor(solver = \"lbfgs\",max_iter = 400, random_state = 17),\n",
    "                  \"MLR\" : linear_model.LinearRegression()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get scores for DCAA\n",
    "\n",
    "y_pred_DCAA = dict()\n",
    "r2_DCAA_cv = dict()\n",
    "rmse_DCAA_cv = dict()\n",
    "r2_DCAA_ext = dict ()\n",
    "rmse_DCAA_ext = dict()\n",
    "\n",
    "\n",
    "reg_list_DCAA = DCAA_regressors.keys()\n",
    "\n",
    "for a in reg_list_DCAA:\n",
    "    DCAA_regressors[a] = DCAA_regressors[a].fit(X_train_scaled, y_train[:,0])\n",
    "    y_pred_DCAA[a] = DCAA_regressors[a].predict(X_test_scaled)\n",
    "    \n",
    "    r2_DCAA_cv[a] = model_selection.cross_validate(DCAA_regressors[a], X_train_scaled,y_train[:,0], scoring = \"r2\", cv =10 )\n",
    "    r2_DCAA_cv[a] = mean(r2_DCAA_cv[a][\"test_score\"])\n",
    "    rmse_DCAA_cv[a] = model_selection.cross_validate(DCAA_regressors[a], X_train_scaled,y_train[:,0], scoring = \"neg_root_mean_squared_error\", cv =10 )\n",
    "    rmse_DCAA_cv[a] = -mean(rmse_DCAA_cv[a][\"test_score\"])\n",
    "    \n",
    "    r2_DCAA_ext[a] = DCAA_regressors[a].score(X_test_scaled, y_test[:,0])\n",
    "    rmse_DCAA_ext[a] = sqrt(mean_squared_error(y_test[:,0], (y_pred_DCAA[a])))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get scores for TCAA\n",
    "\n",
    "y_pred_TCAA = dict()\n",
    "\n",
    "r2_TCAA_cv = dict()\n",
    "rmse_TCAA_cv = dict()\n",
    "r2_TCAA_ext = dict ()\n",
    "rmse_TCAA_ext = dict()\n",
    "\n",
    "\n",
    "reg_list_TCAA = TCAA_regressors.keys()\n",
    "\n",
    "for a in reg_list_TCAA:\n",
    "    TCAA_regressors[a] = TCAA_regressors[a].fit(X_train_scaled, y_train[:,1])\n",
    "    y_pred_TCAA[a] = TCAA_regressors[a].predict(X_test_scaled)\n",
    "    \n",
    "    r2_TCAA_cv[a] = model_selection.cross_validate(TCAA_regressors[a], X_train_scaled,y_train[:,1], scoring = \"r2\", cv =10 )\n",
    "    r2_TCAA_cv[a] = mean(r2_TCAA_cv[a][\"test_score\"])\n",
    "    rmse_TCAA_cv[a] = model_selection.cross_validate(TCAA_regressors[a], X_train_scaled,y_train[:,1], scoring = \"neg_root_mean_squared_error\", cv =10 )\n",
    "    rmse_TCAA_cv[a] = -mean(rmse_TCAA_cv[a][\"test_score\"])\n",
    "    r2_TCAA_ext[a] = TCAA_regressors[a].score(X_test_scaled, y_test[:,1])\n",
    "    rmse_TCAA_ext[a] = sqrt(mean_squared_error(y_test[:,1], (y_pred_TCAA[a])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'RF': 0.18143943633705648, 'SVR_{rbf}': 0.21932276902185824, 'SVR_{linear}': -3.5667067692779093, 'MLP': -0.4917573171597518, 'MLR': -1.7832187838355346e+24}\n",
      "{'RF': 1.2148145740425185, 'SVR_{rbf}': 1.155126601344284, 'SVR_{linear}': 2.4255885290873795, 'MLP': 1.5104533104870868, 'MLR': 686014979619.023}\n",
      "{'RF': 0.3631855069397599, 'SVR_{rbf}': 0.4896203220903964, 'SVR_{linear}': -5.837223655627317, 'MLP': 0.12804587501826914, 'MLR': -7.904012819174876e+22}\n",
      "{'RF': 1.0609381801689326, 'SVR_{rbf}': 0.9497959121188009, 'SVR_{linear}': 3.4763500616892227, 'MLP': 1.2414534153037067, 'MLR': 373772570507.972}\n"
     ]
    }
   ],
   "source": [
    "print(r2_DCAA_cv)\n",
    "print(rmse_DCAA_cv)\n",
    "print(r2_DCAA_ext)\n",
    "print(rmse_DCAA_ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'RF': 0.5672337518479714, 'SVR_{rbf}': 0.5177181576383716, 'SVR_{linear}': -3.3765006419623194, 'MLP': 0.156825287662926, 'MLR': -2.5190593521206196e+23}\n",
      "{'RF': 1.2029191568160351, 'SVR_{rbf}': 1.258792623899648, 'SVR_{linear}': 3.4822958723233337, 'MLP': 1.6593527684764997, 'MLR': 500751802977.23016}\n",
      "{'RF': 0.4773382788506608, 'SVR_{rbf}': 0.6481488494104946, 'SVR_{linear}': -2.419134457221161, 'MLP': 0.13319932390565714, 'MLR': -9.319042025577477e+23}\n",
      "{'RF': 1.296242799122037, 'SVR_{rbf}': 1.063544087170145, 'SVR_{linear}': 3.315386002383371, 'MLP': 1.6693047546331774, 'MLR': 1730858817364.3389}\n"
     ]
    }
   ],
   "source": [
    "print(r2_TCAA_cv)\n",
    "print(rmse_TCAA_cv)\n",
    "print(r2_TCAA_ext)\n",
    "print(rmse_TCAA_ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE_{CV}</th>\n",
       "      <th>Q^2</th>\n",
       "      <th>RMSE_{ext}</th>\n",
       "      <th>R^2_{ext}</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>1.214815e+00</td>\n",
       "      <td>1.814394e-01</td>\n",
       "      <td>1.060938e+00</td>\n",
       "      <td>3.631855e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR_{rbf}</th>\n",
       "      <td>1.155127e+00</td>\n",
       "      <td>2.193228e-01</td>\n",
       "      <td>9.497959e-01</td>\n",
       "      <td>4.896203e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR_{linear}</th>\n",
       "      <td>2.425589e+00</td>\n",
       "      <td>-3.566707e+00</td>\n",
       "      <td>3.476350e+00</td>\n",
       "      <td>-5.837224e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>1.510453e+00</td>\n",
       "      <td>-4.917573e-01</td>\n",
       "      <td>1.241453e+00</td>\n",
       "      <td>1.280459e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLR</th>\n",
       "      <td>6.860150e+11</td>\n",
       "      <td>-1.783219e+24</td>\n",
       "      <td>3.737726e+11</td>\n",
       "      <td>-7.904013e+22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 RMSE_{CV}           Q^2    RMSE_{ext}     R^2_{ext}\n",
       "RF            1.214815e+00  1.814394e-01  1.060938e+00  3.631855e-01\n",
       "SVR_{rbf}     1.155127e+00  2.193228e-01  9.497959e-01  4.896203e-01\n",
       "SVR_{linear}  2.425589e+00 -3.566707e+00  3.476350e+00 -5.837224e+00\n",
       "MLP           1.510453e+00 -4.917573e-01  1.241453e+00  1.280459e-01\n",
       "MLR           6.860150e+11 -1.783219e+24  3.737726e+11 -7.904013e+22"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DCAA = {\"RMSE_{CV}\" : rmse_DCAA_cv,\n",
    "        \"Q^2\" :r2_DCAA_cv,\n",
    "       \"RMSE_{ext}\" : rmse_DCAA_ext,\n",
    "       \"R^2_{ext}\" : r2_DCAA_ext}\n",
    "\n",
    "DCAA_df = pd.DataFrame.from_dict(DCAA)\n",
    "\n",
    "DCAA_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE_{CV}</th>\n",
       "      <th>Q^2</th>\n",
       "      <th>RMSE_{ext}</th>\n",
       "      <th>R^2_{ext}</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>1.202919e+00</td>\n",
       "      <td>5.672338e-01</td>\n",
       "      <td>1.296243e+00</td>\n",
       "      <td>4.773383e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR_{rbf}</th>\n",
       "      <td>1.258793e+00</td>\n",
       "      <td>5.177182e-01</td>\n",
       "      <td>1.063544e+00</td>\n",
       "      <td>6.481488e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR_{linear}</th>\n",
       "      <td>3.482296e+00</td>\n",
       "      <td>-3.376501e+00</td>\n",
       "      <td>3.315386e+00</td>\n",
       "      <td>-2.419134e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>1.659353e+00</td>\n",
       "      <td>1.568253e-01</td>\n",
       "      <td>1.669305e+00</td>\n",
       "      <td>1.331993e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLR</th>\n",
       "      <td>5.007518e+11</td>\n",
       "      <td>-2.519059e+23</td>\n",
       "      <td>1.730859e+12</td>\n",
       "      <td>-9.319042e+23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 RMSE_{CV}           Q^2    RMSE_{ext}     R^2_{ext}\n",
       "RF            1.202919e+00  5.672338e-01  1.296243e+00  4.773383e-01\n",
       "SVR_{rbf}     1.258793e+00  5.177182e-01  1.063544e+00  6.481488e-01\n",
       "SVR_{linear}  3.482296e+00 -3.376501e+00  3.315386e+00 -2.419134e+00\n",
       "MLP           1.659353e+00  1.568253e-01  1.669305e+00  1.331993e-01\n",
       "MLR           5.007518e+11 -2.519059e+23  1.730859e+12 -9.319042e+23"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TCAA = {\"RMSE_{CV}\" : rmse_TCAA_cv,\n",
    "        \"Q^2\" :r2_TCAA_cv,\n",
    "       \"RMSE_{ext}\" : rmse_TCAA_ext,\n",
    "       \"R^2_{ext}\" : r2_TCAA_ext}\n",
    "\n",
    "TCAA_df = pd.DataFrame.from_dict(TCAA)\n",
    "\n",
    "TCAA_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_dict = {\"DCAA \": DCAA,\n",
    "             \"TCAA\" : TCAA}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrr}\n",
      "\\toprule\n",
      "{} &     RMSE\\_\\{CV\\} &           Q\\textasciicircum 2 &    RMSE\\_\\{ext\\} &     R\\textasciicircum 2\\_\\{ext\\} \\\\\n",
      "\\midrule\n",
      "RF           &  1.214815e+00 &  1.814394e-01 &  1.060938e+00 &  3.631855e-01 \\\\\n",
      "SVR\\_\\{rbf\\}    &  1.155127e+00 &  2.193228e-01 &  9.497959e-01 &  4.896203e-01 \\\\\n",
      "SVR\\_\\{linear\\} &  2.425589e+00 & -3.566707e+00 &  3.476350e+00 & -5.837224e+00 \\\\\n",
      "MLP          &  1.510453e+00 & -4.917573e-01 &  1.241453e+00 &  1.280459e-01 \\\\\n",
      "MLR          &  6.860150e+11 & -1.783219e+24 &  3.737726e+11 & -7.904013e+22 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame.to_latex(DCAA_df, index = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\\begin{array}{ccccc}\n",
    "\\hline & & DCAA & & \\\\\n",
    "\\hline  & RMSE_{CV} & Q^2 & RMSE_{ext} & R^2_{ext}  \\\\\\hline\n",
    "RF           &  1.21 &  0.18&  1.06 &  0.36 \\\\\n",
    "SVR_{rbf}    &  1.16 &  0.32 &  0.95 &  0.52 \\\\\n",
    "SVR_{linear} &  2.43 & -3.57 &  3.47 & -5.84 \\\\\n",
    "\\end{array}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrr}\n",
      "\\toprule\n",
      "{} &     RMSE\\_\\{CV\\} &           Q\\textasciicircum 2 &    RMSE\\_\\{ext\\} &     R\\textasciicircum 2\\_\\{ext\\} \\\\\n",
      "\\midrule\n",
      "RF           &  1.202919e+00 &  5.672338e-01 &  1.296243e+00 &  4.773383e-01 \\\\\n",
      "SVR\\_\\{rbf\\}    &  1.258793e+00 &  5.177182e-01 &  1.063544e+00 &  6.481488e-01 \\\\\n",
      "SVR\\_\\{linear\\} &  3.482296e+00 & -3.376501e+00 &  3.315386e+00 & -2.419134e+00 \\\\\n",
      "MLP          &  1.659353e+00 &  1.568253e-01 &  1.669305e+00 &  1.331993e-01 \\\\\n",
      "MLR          &  5.007518e+11 & -2.519059e+23 &  1.730859e+12 & -9.319042e+23 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame.to_latex(TCAA_df, index = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\\begin{array}{ccccc}\n",
    "\\hline & & TCAA & & \\\\\n",
    "\\hline  & RMSE_{CV} & Q^2 & RMSE_{ext} & R^2_{ext}  \\\\\\hline\n",
    "RF           &  1.20 &  0.57 &  1.27 &  0.48 \\\\\n",
    "SVR_{rbf}    &  1.26 &  0.52 &  1.06 &  0.65 \\\\\n",
    "\\end{array}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\\begin{array}{ccccc}\n",
    "\\hline & & DCAA & & \\\\\n",
    "\\hline  & RMSE_{CV} & Q^2 & RMSE_{ext} & R^2_{ext}  \\\\\\hline\n",
    "RF           &  1.21 &  0.18&  1.06 &  0.36 \\\\\n",
    "SVR_{rbf}    &  1.16 &  0.32 &  0.95 &  0.52 \\\\\n",
    "\\hline & & TCAA & & \\\\\\hline\n",
    "RF           &  1.20 &  0.57 &  1.27 &  0.48 \\\\\n",
    "SVR_{rbf}    &  1.26 &  0.52 &  1.06 &  0.65 \\\\\\hline\n",
    "\\end{array}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{array}{ccccc}\n",
    "\\hline & & DCAA (optimized) & &  & & DCAA (default) & & \\\\\n",
    "\\hline  & RMSE_{CV} & Q^2 & RMSE_{ext} & R^2_{ext}  & RMSE_{CV} & Q^2 & RMSE_{ext} & R^2_{ext}  \\\\\\hline\n",
    "RF           &  1.21 &  0.18&  1.06 &  0.36  &  1.26 &  0.08 &  1.01 &  0.42 \\\\\n",
    "SVR_{rbf}    &  1.16 &  0.32 &  0.95 &  0.52  &  1.19 &  0.26 &  0.99 &  0.44 \\\\\n",
    "\\hline & & TCAA (optimized) & &  & & TCAA (default) & & \\\\\\hline\n",
    "RF           &  1.20 &  0.57 &  1.27 &  0.48  &  1.24 &  0.54 &  1.27 &  0.50 \\\\\n",
    "SVR_{rbf}    &  1.26 &  0.52 &  1.06 &  0.65 &  1.38 &  0.44 &  1.20 &  0.55 \\\\\\hline\n",
    "\\end{array}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scale & Support Vector Regression - Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "# training using scaled data\n",
    "\n",
    "DCAA_regressor = svm.SVR(gamma = \"scale\", kernel = \"linear\")\n",
    "DCAA_regressor.fit(X_train_scaled, y_train[:,0])\n",
    "\n",
    "TCAA_regressor = svm.SVR(gamma = \"scale\" , kernel = \"linear\")\n",
    "TCAA_regressor.fit(X_train_scaled, y_train[:,1])\n",
    "\n",
    "HAAFP_regressor = svm.SVR(gamma = \"scale\" , kernel = \"linear\")\n",
    "HAAFP_regressor.fit(X_train_scaled, y_train[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(DCAA_regressor.fit_status_)    # 0 if correctly fitted\n",
    "print(TCAA_regressor.fit_status_)\n",
    "print(HAAFP_regressor.fit_status_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of training set (regression parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_DCAA_train = model_selection.cross_validate(DCAA_regressor, X_train_scaled,y_train[:,0], scoring = \"neg_root_mean_squared_error\", cv =10 )\n",
    "rmse_DCAA_train = -mean(rmse_DCAA_train[\"test_score\"])\n",
    "\n",
    "rmse_TCAA_train = model_selection.cross_validate(TCAA_regressor, X_train_scaled,y_train[:,1], scoring = \"neg_root_mean_squared_error\", cv =10 )\n",
    "rmse_TCAA_train = -mean(rmse_TCAA_train[\"test_score\"])\n",
    "\n",
    "rmse_HAA_train = model_selection.cross_validate(HAAFP_regressor, X_train_scaled,y_train[:,2], scoring = \"neg_root_mean_squared_error\", cv =10 )\n",
    "rmse_HAA_train = -mean(rmse_HAA_train[\"test_score\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_DCAA_train = model_selection.cross_validate(DCAA_regressor, X_train_scaled,y_train[:,0], scoring = \"r2\", cv =10 )\n",
    "r2_DCAA_train = mean(r2_DCAA_train[\"test_score\"])\n",
    "\n",
    "r2_TCAA_train = model_selection.cross_validate(TCAA_regressor, X_train_scaled,y_train[:,1], scoring = \"r2\", cv =10 )\n",
    "r2_TCAA_train = mean(r2_TCAA_train[\"test_score\"])\n",
    "\n",
    "r2_HAAFP_train = model_selection.cross_validate(HAAFP_regressor, X_train_scaled,y_train[:,2], scoring = \"r2\", cv =10 )\n",
    "r2_HAAFP_train = mean(r2_HAAFP_train[\"test_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"DCAA_Q :\",  r2_DCAA_train)                 \n",
    "print(\"TCAA_Q :\", r2_TCAA_train)\n",
    "print(\"HAAs_Q :\", r2_HAAFP_train)\n",
    "\n",
    "print(\"DCAA_RMSE :\",  rmse_DCAA_train)                 \n",
    "print(\"TCAA_RMSE :\", rmse_TCAA_train)\n",
    "print(\"HAAs_RMSE :\", rmse_HAA_train) \n",
    "\n",
    "                                                        #The coefficient R^2 is defined as (1 - u/v), where u is the residual sum of squares ((y_true - y_pred) ** 2).sum() and v is the total sum of squares ((y_true - y_true.mean()) ** 2).sum(). The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a R^2 score of 0.0.\n",
    "parameters = DCAA_regressor.get_params()              # Return the parameters used in this estimator\n",
    "parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of test set (regression parameters) -  External Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_DCAA = DCAA_regressor.predict(X_test_scaled)\n",
    "y_pred_TCAA = TCAA_regressor.predict(X_test_scaled)\n",
    "y_pred_HAAFP = HAAFP_regressor.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r2 ext\n",
    "\n",
    "score_DCAA = DCAA_regressor.score(X_test_scaled, y_test[:,0])           #Return the coefficient of determination R^2 of the prediction.\n",
    "score_TCAA = TCAA_regressor.score(X_test_scaled, y_test[:,1])\n",
    "score_HAAFP = HAAFP_regressor.score(X_test_scaled, y_test[:,2])\n",
    "print(\"DCAA :\",  score_DCAA)                 \n",
    "print(\"TCAA :\", score_TCAA)\n",
    "print(\"HAAs :\", score_HAAFP)                           #The coefficient R^2 is defined as (1 - u/v), where u is the residual sum of squares ((y_true - y_pred) ** 2).sum() and v is the total sum of squares ((y_true - y_true.mean()) ** 2).sum(). The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a R^2 score of 0.0.\n",
    "parameters = DCAA_regressor.get_params()              # Return the parameters used in this estimator\n",
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# RMSE ext\n",
    "DCAA_rmse = sqrt(mean_squared_error(y_test[:,0], (y_pred_DCAA)))\n",
    "TCAA_rmse = sqrt(mean_squared_error(y_test[:,1], (y_pred_TCAA)))\n",
    "HAAFP_rmse = sqrt(mean_squared_error(y_test[:,2], (y_pred_HAAFP)))\n",
    "\n",
    "\n",
    "print(\"DCAA: RMSE =  %f \" %DCAA_rmse)\n",
    "print(\"TCAA: RMSE =  %f\" %TCAA_rmse)\n",
    "print(\"HAAFP: RMSE =  %f\" %HAAFP_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "fig, axs = plt.subplots(2, sharex=True, sharey=True, figsize = (15,4))\n",
    "\n",
    "\n",
    "p1 = plt.subplot(131)\n",
    "p1.axis([-.2, 8, -.2, 8])\n",
    "p1.scatter((y_train[:,0]), (DCAA_regressor.predict(scaler.transform(X_train))), color='orange')\n",
    "p1.scatter((y_test[:,0]), (y_pred_DCAA), color = \"blue\")\n",
    "p1.plot([-1, 8], [-1, 8], color='r')\n",
    "p1.set_title('DCAAFP')\n",
    "p1.text(4,7,\"RMSE$_{CV}$ = %f\" %rmse_DCAA_train, horizontalalignment = \"center\", fontsize = 10)\n",
    "p1.text(4,6.5,\"Q$^{2}$ = %f\" %r2_DCAA_train, horizontalalignment = \"center\", fontsize = 10)\n",
    "\n",
    "plt.ylabel(\"Predicted values (log scale)\")\n",
    "\n",
    "p2 = plt.subplot(132)\n",
    "p2.axis([-.5, 8, -.5, 8])\n",
    "p2.scatter((y_train[:,1]), (TCAA_regressor.predict(scaler.transform(X_train))), color='orange')\n",
    "p2.scatter((y_test[:,1]), (y_pred_TCAA), color = \"blue\")\n",
    "p2.plot([-1, 8], [-1, 8], color='r')\n",
    "p2.legend((\"_fit\",\"Train\",\"Test\" ), edgecolor = \"black\", mode = \"none\", loc = \"upper left\")\n",
    "p2.set_title('TCAAFP')\n",
    "\n",
    "p2.text(4,7,\"RMSE$_{CV}$ = %f\" %rmse_TCAA_train, horizontalalignment = \"center\", fontsize = 10)\n",
    "p2.text(4,6.5,\"Q$^{2}$ = %f\" %r2_TCAA_train, horizontalalignment = \"center\", fontsize = 10)\n",
    "\n",
    "\n",
    "\n",
    "plt.text(-2,-2,\"Experimental values (log scale)\", horizontalalignment = \"center\", fontsize = 10)\n",
    "\n",
    "\n",
    "plt.savefig('../Jupyter/results/figures/simplified_SVR_linear_20200331.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scale & Support Vector Regression - RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training using scaled data\n",
    "\n",
    "DCAA_regressor = svm.SVR(gamma = \"scale\")\n",
    "DCAA_regressor.fit(X_train_scaled, y_train[:,0])\n",
    "\n",
    "TCAA_regressor = svm.SVR(gamma = \"scale\")\n",
    "TCAA_regressor.fit(X_train_scaled, y_train[:,1])\n",
    "\n",
    "HAAFP_regressor = svm.SVR(gamma = \"scale\")\n",
    "HAAFP_regressor.fit(X_train_scaled, y_train[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(DCAA_regressor.fit_status_)    # 0 if correctly fitted\n",
    "print(TCAA_regressor.fit_status_)\n",
    "print(HAAFP_regressor.fit_status_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of training set (regression parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_DCAA_train = model_selection.cross_validate(DCAA_regressor, X_train_scaled,y_train[:,0], scoring = \"neg_root_mean_squared_error\", cv =10 )\n",
    "rmse_DCAA_train = -mean(rmse_DCAA_train[\"test_score\"])\n",
    "\n",
    "rmse_TCAA_train = model_selection.cross_validate(TCAA_regressor, X_train_scaled,y_train[:,1], scoring = \"neg_root_mean_squared_error\", cv =10 )\n",
    "rmse_TCAA_train = -mean(rmse_TCAA_train[\"test_score\"])\n",
    "\n",
    "rmse_HAA_train = model_selection.cross_validate(HAAFP_regressor, X_train_scaled,y_train[:,2], scoring = \"neg_root_mean_squared_error\", cv =10 )\n",
    "rmse_HAA_train = -mean(rmse_HAA_train[\"test_score\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_DCAA_train = model_selection.cross_validate(DCAA_regressor, X_train_scaled,y_train[:,0], scoring = \"r2\", cv =10 )\n",
    "r2_DCAA_train = mean(r2_DCAA_train[\"test_score\"])\n",
    "\n",
    "r2_TCAA_train = model_selection.cross_validate(TCAA_regressor, X_train_scaled,y_train[:,1], scoring = \"r2\", cv =10 )\n",
    "r2_TCAA_train = mean(r2_TCAA_train[\"test_score\"])\n",
    "\n",
    "r2_HAAFP_train = model_selection.cross_validate(HAAFP_regressor, X_train_scaled,y_train[:,2], scoring = \"r2\", cv =10 )\n",
    "r2_HAAFP_train = mean(r2_HAAFP_train[\"test_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"DCAA_Q :\",  r2_DCAA_train)                 \n",
    "print(\"TCAA_Q :\", r2_TCAA_train)\n",
    "print(\"HAAs_Q :\", r2_HAAFP_train)\n",
    "\n",
    "print(\"DCAA_RMSE :\",  rmse_DCAA_train)                 \n",
    "print(\"TCAA_RMSE :\", rmse_TCAA_train)\n",
    "print(\"HAAs_RMSE :\", rmse_HAA_train) \n",
    "\n",
    "                                                        #The coefficient R^2 is defined as (1 - u/v), where u is the residual sum of squares ((y_true - y_pred) ** 2).sum() and v is the total sum of squares ((y_true - y_true.mean()) ** 2).sum(). The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a R^2 score of 0.0.\n",
    "parameters = DCAA_regressor.get_params()              # Return the parameters used in this estimator\n",
    "parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of test set (regression parameters) -  External Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_DCAA = DCAA_regressor.predict(X_test_scaled)\n",
    "y_pred_TCAA = TCAA_regressor.predict(X_test_scaled)\n",
    "y_pred_HAAFP = HAAFP_regressor.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#R2 ext\n",
    "\n",
    "score_DCAA = DCAA_regressor.score(X_test_scaled, y_test[:,0])           #Return the coefficient of determination R^2 of the prediction.\n",
    "score_TCAA = TCAA_regressor.score(X_test_scaled, y_test[:,1])\n",
    "score_HAAFP = HAAFP_regressor.score(X_test_scaled, y_test[:,2])\n",
    "print(\"DCAA :\",  score_DCAA)                 \n",
    "print(\"TCAA :\", score_TCAA)\n",
    "print(\"HAAs :\", score_HAAFP)                           #The coefficient R^2 is defined as (1 - u/v), where u is the residual sum of squares ((y_true - y_pred) ** 2).sum() and v is the total sum of squares ((y_true - y_true.mean()) ** 2).sum(). The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a R^2 score of 0.0.\n",
    "parameters = DCAA_regressor.get_params()              # Return the parameters used in this estimator\n",
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# RMSE ext\n",
    "DCAA_rmse = sqrt(mean_squared_error(y_test[:,0], (y_pred_DCAA)))\n",
    "TCAA_rmse = sqrt(mean_squared_error(y_test[:,1], (y_pred_TCAA)))\n",
    "HAAFP_rmse = sqrt(mean_squared_error(y_test[:,2], (y_pred_HAAFP)))\n",
    "\n",
    "\n",
    "print(\"DCAA: RMSE =  %f\" %DCAA_rmse)\n",
    "print(\"TCAA: RMSE =  %f\" %TCAA_rmse)\n",
    "print(\"HAAFP: RMSE =  %f\" %HAAFP_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, sharex=True, sharey=True, figsize = (15,4))\n",
    "\n",
    "\n",
    "p1 = plt.subplot(131)\n",
    "p1.axis([-.2, 8, -.2, 8])\n",
    "p1.scatter((y_train[:,0]), (DCAA_regressor.predict(scaler.transform(X_train))), color='orange')\n",
    "p1.scatter((y_test[:,0]), (y_pred_DCAA), color = \"blue\")\n",
    "p1.plot([-1, 8], [-1, 8], color='r')\n",
    "p1.set_title('DCAAFP')\n",
    "p1.text(4,7,\"RMSE$_{CV}$ = %f\" %rmse_DCAA_train, horizontalalignment = \"center\", fontsize = 10)\n",
    "p1.text(4,6.5,\"Q$^{2}$ = %f\" %r2_DCAA_train, horizontalalignment = \"center\", fontsize = 10)\n",
    "\n",
    "plt.ylabel(\"Predicted values (log scale)\")\n",
    "\n",
    "p2 = plt.subplot(132)\n",
    "p2.axis([-.5, 8, -.5, 8])\n",
    "p2.scatter((y_train[:,1]), (TCAA_regressor.predict(scaler.transform(X_train))), color='orange')\n",
    "p2.scatter((y_test[:,1]), (y_pred_TCAA), color = \"blue\")\n",
    "p2.plot([-1, 8], [-1, 8], color='r')\n",
    "p2.legend((\"_fit\",\"Train\",\"Test\" ), edgecolor = \"black\", mode = \"none\", loc = \"upper left\")\n",
    "p2.set_title('TCAAFP')\n",
    "\n",
    "p2.text(4,7,\"RMSE$_{CV}$ = %f\" %rmse_TCAA_train, horizontalalignment = \"center\", fontsize = 10)\n",
    "p2.text(4,6.5,\"Q$^{2}$ = %f\" %r2_TCAA_train, horizontalalignment = \"center\", fontsize = 10)\n",
    "\n",
    "\n",
    "\n",
    "plt.text(-2,-2,\"Experimental values (log scale)\", horizontalalignment = \"center\", fontsize = 10)\n",
    "\n",
    "\n",
    "\n",
    "plt.savefig('../Jupyter/results/figures/simplified_SVR_rbf_20200331.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DCAA_RF_regressor = RandomForestRegressor(random_state = 17)\n",
    "DCAA_RF_regressor.fit(X_train, y_train[:,0])\n",
    "\n",
    "TCAA_RF_regressor = RandomForestRegressor(random_state = 17)\n",
    "TCAA_RF_regressor.fit(X_train, y_train[:,1])\n",
    "\n",
    "HAAFP_RF_regressor = RandomForestRegressor(random_state = 17)\n",
    "HAAFP_RF_regressor.fit(X_train, y_train[:,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of training set (regression parameters) - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R2 CV\n",
    "r2_DCAA_RF_train = model_selection.cross_validate(DCAA_RF_regressor, X_train_scaled,y_train[:,0], scoring = \"r2\", cv =10 )\n",
    "r2_DCAA_RF_train = mean(r2_DCAA_RF_train[\"test_score\"])\n",
    "\n",
    "r2_TCAA_RF_train = model_selection.cross_validate(TCAA_RF_regressor, X_train_scaled,y_train[:,1], scoring = \"r2\", cv =10 )\n",
    "r2_TCAA_RF_train = mean(r2_TCAA_RF_train[\"test_score\"])\n",
    "\n",
    "r2_HAAFP_RF_train = model_selection.cross_validate(HAAFP_RF_regressor, X_train_scaled,y_train[:,2], scoring = \"r2\", cv =10 )\n",
    "r2_HAAFP_RF_train = mean(r2_HAAFP_RF_train[\"test_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE CV\n",
    "rmse_DCAA_RF_train = model_selection.cross_validate(DCAA_RF_regressor, X_train_scaled,y_train[:,0], scoring = \"neg_root_mean_squared_error\", cv =10 )\n",
    "rmse_DCAA_RF_train = -mean(rmse_DCAA_RF_train[\"test_score\"])\n",
    "\n",
    "rmse_TCAA_RF_train = model_selection.cross_validate(TCAA_RF_regressor, X_train_scaled,y_train[:,1], scoring = \"neg_root_mean_squared_error\", cv =10 )\n",
    "rmse_TCAA_RF_train = -mean(rmse_TCAA_RF_train[\"test_score\"])\n",
    "\n",
    "rmse_HAAFP_RF_train = model_selection.cross_validate(HAAFP_RF_regressor, X_train_scaled,y_train[:,2], scoring = \"neg_root_mean_squared_error\", cv =10 )\n",
    "rmse_HAAFP_RF_train = -mean(rmse_HAAFP_RF_train[\"test_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"DCAA :\",  r2_DCAA_RF_train)                 \n",
    "print(\"TCAA :\", r2_TCAA_RF_train)\n",
    "print(\"HAAs :\", r2_HAAFP_RF_train)  \n",
    "\n",
    "print(\"DCAA :\",  rmse_DCAA_RF_train)                 \n",
    "print(\"TCAA :\", rmse_TCAA_RF_train)\n",
    "print(\"HAAs :\", rmse_HAAFP_RF_train)                           #The coefficient R^2 is defined as (1 - u/v), where u is the residual sum of squares ((y_true - y_pred) ** 2).sum() and v is the total sum of squares ((y_true - y_true.mean()) ** 2).sum(). The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a R^2 score of 0.0.\n",
    "parameters = DCAA_RF_regressor.get_params()              # Return the parameters used in this estimator\n",
    "parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of test set (regression parameters) -  External Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_RF_DCAA = DCAA_RF_regressor.predict(X_test)\n",
    "y_pred_RF_TCAA = TCAA_RF_regressor.predict(X_test)\n",
    "y_pred_RF_HAAFP = HAAFP_RF_regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R2 of prediction with the test set\n",
    "\n",
    "score_DCAA_RF = DCAA_RF_regressor.score(X_test, y_test[:,0])           #Return the coefficient of determination R^2 of the prediction.\n",
    "score_TCAA_RF = TCAA_RF_regressor.score(X_test, y_test[:,1])\n",
    "score_HAAFP_RF = HAAFP_RF_regressor.score(X_test, y_test[:,2])\n",
    "print(\"DCAA :\",  score_DCAA_RF)                 \n",
    "print(\"TCAA :\", score_TCAA_RF)\n",
    "print(\"HAAs :\", score_HAAFP_RF)                           #The coefficient R^2 is defined as (1 - u/v), where u is the residual sum of squares ((y_true - y_pred) ** 2).sum() and v is the total sum of squares ((y_true - y_true.mean()) ** 2).sum(). The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a R^2 score of 0.0.\n",
    "parameters = DCAA_RF_regressor.get_params()              # Return the parameters used in this estimator\n",
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# RMSE external\n",
    "DCAA_rmse = sqrt(mean_squared_error(y_test[:,0], (y_pred_RF_DCAA)))\n",
    "TCAA_rmse = sqrt(mean_squared_error(y_test[:,1], (y_pred_RF_TCAA)))\n",
    "HAAFP_rmse = sqrt(mean_squared_error(y_test[:,2], (y_pred_RF_HAAFP)))\n",
    "\n",
    "\n",
    "print(\"DCAA: RMSE =  %f\" %DCAA_rmse)\n",
    "print(\"TCAA: RMSE =  %f \" %TCAA_rmse)\n",
    "print(\"HAAFP: RMSE =  %f\" %HAAFP_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, sharex=True, sharey=True, figsize = (15,4))\n",
    "\n",
    "\n",
    "p1 = plt.subplot(131)\n",
    "p1.axis([-0.5, 7, -0.5, 7])\n",
    "p1.scatter(y_train[:,0], DCAA_RF_regressor.predict(X_train), color='orange')\n",
    "p1.scatter(y_test[:,0], y_pred_RF_DCAA, color = \"blue\")\n",
    "p1.plot([-0.5, 7], [-0.5, 7], color='r')\n",
    "p1.set_title('DCAA')\n",
    "p1.set_ylabel(\"Predicted values (log scale)\")\n",
    "\n",
    "p1.text(4,6.2,\"RMSE$_{CV}$ = %f\" %rmse_DCAA_RF_train, horizontalalignment = \"center\", fontsize = 10)\n",
    "p1.text(4,5.7,\"Q$^{2}$ = %f\" %r2_DCAA_RF_train, horizontalalignment = \"center\", fontsize = 10)\n",
    "\n",
    "\n",
    "p2 = plt.subplot(132)\n",
    "p2.axis([-0.5, 7, -0.5, 7])\n",
    "p2.scatter(y_train[:,1], TCAA_RF_regressor.predict(X_train), color='orange')\n",
    "p2.scatter(y_test[:,1], y_pred_RF_TCAA, color='blue')\n",
    "p2.plot([-0.5, 7], [-0.5, 7], color='r')\n",
    "p2.set_title('TCAA')\n",
    "p2.set_xlabel(\"Experimental values (log scale)\")\n",
    "\n",
    "p2.text(4,6.2,\"RMSE$_{CV}$ = %f\" %rmse_TCAA_RF_train, horizontalalignment = \"center\", fontsize = 10)\n",
    "p2.text(4,5.7,\"Q$^{2}$ = %f\" %r2_TCAA_RF_train, horizontalalignment = \"center\", fontsize = 10)\n",
    "\n",
    "p2.legend((\"_fit\",\"Train\",\"Test\" ), edgecolor = \"black\", mode = \"none\", loc = \"upper left\")\n",
    "\n",
    "plt.text(-2,-2,\"Experimental values (log scale)\", horizontalalignment = \"center\", fontsize = 10)\n",
    "\n",
    "plt.savefig('../Jupyter/results/figures/simplified_RF_20200331.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilayer Perceptron Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DCAA_mlp_regressor = MLPRegressor()\n",
    "DCAA_mlp_regressor.fit(X_train_scaled, y_train[:,0])\n",
    "\n",
    "TCAA_mlp_regressor = MLPRegressor()\n",
    "TCAA_mlp_regressor.fit(X_train_scaled, y_train[:,1])\n",
    "\n",
    "HAAFP_mlp_regressor = MLPRegressor()\n",
    "HAAFP_mlp_regressor.fit(X_train_scaled, y_train[:,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of training set (regression parameters) - MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Q2\n",
    "\n",
    "r2_DCAA_mlp_train = model_selection.cross_validate(DCAA_mlp_regressor, X_train_scaled,y_train[:,0], scoring = \"r2\", cv =10 )\n",
    "r2_DCAA_mlp_train = mean(r2_DCAA_mlp_train[\"test_score\"])\n",
    "\n",
    "r2_TCAA_mlp_train = model_selection.cross_validate(TCAA_mlp_regressor, X_train_scaled,y_train[:,1], scoring = \"r2\", cv =10 )\n",
    "r2_TCAA_mlp_train = mean(r2_TCAA_mlp_train[\"test_score\"])\n",
    "\n",
    "r2_HAAFP_mlp_train = model_selection.cross_validate(HAAFP_mlp_regressor, X_train_scaled,y_train[:,2], scoring = \"r2\", cv =10 )\n",
    "r2_HAAFP_mlp_train = mean(r2_HAAFP_mlp_train[\"test_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate RMSE cv\n",
    "\n",
    "rmse_DCAA_mlp_train = model_selection.cross_validate(DCAA_mlp_regressor, X_train_scaled,y_train[:,0], scoring = \"neg_root_mean_squared_error\", cv =10 )\n",
    "rmse_DCAA_mlp_train = -mean(rmse_DCAA_mlp_train[\"test_score\"])\n",
    "\n",
    "rmse_TCAA_mlp_train = model_selection.cross_validate(TCAA_mlp_regressor, X_train_scaled,y_train[:,1], scoring = \"neg_root_mean_squared_error\", cv =10 )\n",
    "rmse_TCAA_mlp_train = -mean(rmse_TCAA_mlp_train[\"test_score\"])\n",
    "\n",
    "rmse_HAAFP_mlp_train = model_selection.cross_validate(HAAFP_mlp_regressor, X_train_scaled,y_train[:,2], scoring = \"neg_root_mean_squared_error\", cv =10 )\n",
    "rmse_HAAFP_mlp_train = -mean(rmse_HAAFP_mlp_train[\"test_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"DCAA :\",  r2_DCAA_mlp_train)                 \n",
    "print(\"TCAA :\", r2_TCAA_mlp_train)\n",
    "print(\"HAAs :\", r2_HAAFP_mlp_train) \n",
    "\n",
    "\n",
    "print(\"DCAA :\",  rmse_DCAA_mlp_train)                 \n",
    "print(\"TCAA :\", rmse_TCAA_mlp_train)\n",
    "print(\"HAAs :\", rmse_HAAFP_mlp_train)\n",
    "\n",
    "#The coefficient R^2 is defined as (1 - u/v), where u is the residual sum of squares ((y_true - y_pred) ** 2).sum() and v is the total sum of squares ((y_true - y_true.mean()) ** 2).sum(). The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a R^2 score of 0.0.\n",
    "parameters = DCAA_mlp_regressor.get_params()              # Return the parameters used in this estimator\n",
    "parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of test set (regression parameters) -  External Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_mlp_DCAA = DCAA_mlp_regressor.predict(X_test_scaled)\n",
    "y_pred_mlp_TCAA = TCAA_mlp_regressor.predict(X_test_scaled)\n",
    "y_pred_mlp_HAAFP = HAAFP_mlp_regressor.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_DCAA_mlp = DCAA_mlp_regressor.score(X_test_scaled, y_test[:,0])           #Return the coefficient of determination R^2 of the prediction.\n",
    "score_TCAA_mlp = TCAA_mlp_regressor.score(X_test_scaled, y_test[:,1])\n",
    "score_HAAFP_mlp = HAAFP_mlp_regressor.score(X_test_scaled, y_test[:,2])\n",
    "print(\"DCAA :\",  score_DCAA_mlp)                 \n",
    "print(\"TCAA :\", score_TCAA_mlp)\n",
    "print(\"HAAs :\", score_HAAFP_mlp)                           #The coefficient R^2 is defined as (1 - u/v), where u is the residual sum of squares ((y_true - y_pred) ** 2).sum() and v is the total sum of squares ((y_true - y_true.mean()) ** 2).sum(). The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a R^2 score of 0.0.\n",
    "parameters = DCAA_mlp_regressor.get_params()              # Return the parameters used in this estimator\n",
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# RMSE\n",
    "DCAA_rmse = sqrt(mean_squared_error(y_test[:,0], (y_pred_mlp_DCAA)))\n",
    "TCAA_rmse = sqrt(mean_squared_error(y_test[:,1], (y_pred_mlp_TCAA)))\n",
    "HAAFP_rmse = sqrt(mean_squared_error(y_test[:,2], (y_pred_mlp_HAAFP)))\n",
    "\n",
    "\n",
    "print(\"DCAA: RMSE =  %f\" %DCAA_rmse)\n",
    "print(\"TCAA: RMSE =  %f\" %TCAA_rmse)\n",
    "print(\"HAAFP: RMSE =  %f\" %HAAFP_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, sharex=True, sharey=True, figsize = (15,4))\n",
    "\n",
    "\n",
    "p1 = plt.subplot(131)\n",
    "p1.axis([-0.5, 7, -0.5, 7])\n",
    "p1.scatter(y_train[:,0], DCAA_mlp_regressor.predict(X_train_scaled), color='orange')\n",
    "p1.scatter(y_test[:,0], y_pred_mlp_DCAA, color = \"blue\")\n",
    "p1.plot([-0.5, 7], [-0.5, 7], color='r')\n",
    "p1.set_title('DCAA')\n",
    "p1.set_ylabel(\"Predicted values (log scale)\")\n",
    "\n",
    "p1.text(4,6.2,\"RMSE$_{CV}$ = %f\" %rmse_DCAA_mlp_train, horizontalalignment = \"center\", fontsize = 10)\n",
    "p1.text(4,5.7,\"Q$^{2}$ = %f\" %r2_DCAA_mlp_train, horizontalalignment = \"center\", fontsize = 10)\n",
    "\n",
    "\n",
    "p2 = plt.subplot(132)\n",
    "p2.axis([-0.5, 7, -0.5, 7])\n",
    "p2.scatter(y_train[:,1], TCAA_mlp_regressor.predict(X_train_scaled), color='orange')\n",
    "p2.scatter(y_test[:,1], y_pred_mlp_TCAA, color='blue')\n",
    "p2.plot([-0.5, 7], [-0.5, 7], color='r')\n",
    "p2.set_title('TCAA')\n",
    "p2.set_xlabel(\"Experimental values (log scale)\")\n",
    "\n",
    "p2.text(4,6.2,\"RMSE$_{CV}$ = %f\" %rmse_TCAA_mlp_train, horizontalalignment = \"center\", fontsize = 10)\n",
    "p2.text(4,5.7,\"Q$^{2}$ = %f\" %r2_TCAA_mlp_train, horizontalalignment = \"center\", fontsize = 10)\n",
    "\n",
    "p2.legend((\"_fit\",\"Train\",\"Test\" ), edgecolor = \"black\", mode = \"none\", loc = \"upper left\")\n",
    "\n",
    "plt.text(-2,-2,\"Experimental values (log scale)\", horizontalalignment = \"center\", fontsize = 10)\n",
    "\n",
    "plt.savefig('../Jupyter/results/figures/simplified_MLP_20200331.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DCAA_mlr_regressor = linear_model.LinearRegression()\n",
    "DCAA_mlr_regressor.fit(X_train_scaled, y_train[:,0])\n",
    "\n",
    "TCAA_mlr_regressor = linear_model.LinearRegression()\n",
    "TCAA_mlr_regressor.fit(X_train_scaled, y_train[:,1])\n",
    "\n",
    "HAAFP_mlr_regressor = linear_model.LinearRegression()\n",
    "HAAFP_mlr_regressor.fit(X_train_scaled, y_train[:,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of training set (regression parameters) - MLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_DCAA_mlr_train = model_selection.cross_validate(DCAA_mlr_regressor, X_train_scaled,y_train[:,0], scoring = \"r2\", cv =10 )\n",
    "r2_DCAA_mlr_train = mean(r2_DCAA_mlr_train[\"test_score\"])\n",
    "\n",
    "r2_TCAA_mlr_train = model_selection.cross_validate(TCAA_mlr_regressor, X_train_scaled,y_train[:,1], scoring = \"r2\", cv =10 )\n",
    "r2_TCAA_mlr_train = mean(r2_TCAA_mlr_train[\"test_score\"])\n",
    "\n",
    "r2_HAAFP_mlr_train = model_selection.cross_validate(HAAFP_mlr_regressor, X_train_scaled,y_train[:,2], scoring = \"r2\", cv =10 )\n",
    "r2_HAAFP_mlr_train = mean(r2_HAAFP_mlr_train[\"test_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_DCAA_mlr_train = model_selection.cross_validate(DCAA_mlr_regressor, X_train_scaled,y_train[:,0], scoring = \"neg_root_mean_squared_error\", cv =10 )\n",
    "rmse_DCAA_mlr_train = -mean(rmse_DCAA_mlr_train[\"test_score\"])\n",
    "\n",
    "rmse_TCAA_mlr_train = model_selection.cross_validate(TCAA_mlr_regressor, X_train_scaled,y_train[:,1], scoring = \"neg_root_mean_squared_error\", cv =10 )\n",
    "rmse_TCAA_mlr_train = -mean(rmse_TCAA_mlr_train[\"test_score\"])\n",
    "\n",
    "rmse_HAAFP_mlr_train = model_selection.cross_validate(HAAFP_mlr_regressor, X_train_scaled,y_train[:,2], scoring = \"neg_root_mean_squared_error\", cv =10 )\n",
    "rmse_HAAFP_mlr_train = -mean(rmse_HAAFP_mlr_train[\"test_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"DCAA :\",  r2_DCAA_mlr_train)                 \n",
    "print(\"TCAA :\", r2_TCAA_mlr_train)\n",
    "print(\"HAAs :\", r2_HAAFP_mlr_train) \n",
    "\n",
    "print(\"DCAA :\",  rmse_DCAA_mlr_train)                 \n",
    "print(\"TCAA :\", rmse_TCAA_mlr_train)\n",
    "print(\"HAAs :\", rmse_HAAFP_mlr_train)                           #The coefficient R^2 is defined as (1 - u/v), where u is the residual sum of squares ((y_true - y_pred) ** 2).sum() and v is the total sum of squares ((y_true - y_true.mean()) ** 2).sum(). The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a R^2 score of 0.0.\n",
    "parameters = DCAA_mlr_regressor.get_params()              # Return the parameters used in this estimator\n",
    "parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of test set (regression parameters) -  External Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_mlr_DCAA = DCAA_mlr_regressor.predict(X_test_scaled)\n",
    "y_pred_mlr_TCAA = TCAA_mlr_regressor.predict(X_test_scaled)\n",
    "y_pred_mlr_HAAFP = HAAFP_mlr_regressor.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R2 external\n",
    "\n",
    "score_DCAA_mlr = DCAA_mlr_regressor.score(X_test_scaled, y_test[:,0])           #Return the coefficient of determination R^2 of the prediction.\n",
    "score_TCAA_mlr = TCAA_mlr_regressor.score(X_test_scaled, y_test[:,1])\n",
    "score_HAAFP_mlr = HAAFP_mlr_regressor.score(X_test_scaled, y_test[:,2])\n",
    "print(\"DCAA :\",  score_DCAA_mlr)                 \n",
    "print(\"TCAA :\", score_TCAA_mlr)\n",
    "print(\"HAAs :\", score_HAAFP_mlr)                           #The coefficient R^2 is defined as (1 - u/v), where u is the residual sum of squares ((y_true - y_pred) ** 2).sum() and v is the total sum of squares ((y_true - y_true.mean()) ** 2).sum(). The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a R^2 score of 0.0.\n",
    "parameters = DCAA_mlr_regressor.get_params()              # Return the parameters used in this estimator\n",
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# RMSE external\n",
    "DCAA_rmse = sqrt(mean_squared_error(y_test[:,0], (y_pred_mlr_DCAA)))\n",
    "TCAA_rmse = sqrt(mean_squared_error(y_test[:,1], (y_pred_mlr_TCAA)))\n",
    "HAAFP_rmse = sqrt(mean_squared_error(y_test[:,2], (y_pred_mlr_HAAFP)))\n",
    "\n",
    "\n",
    "print(\"DCAA: RMSE =  %f\" %DCAA_rmse)\n",
    "print(\"TCAA: RMSE =  %f\" %TCAA_rmse)\n",
    "print(\"HAAFP: RMSE =  %f\" %HAAFP_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, sharex=True, sharey=True, figsize = (15,4))\n",
    "\n",
    "\n",
    "p1 = plt.subplot(131)\n",
    "p1.axis([-0.5, 7, -0.5, 7])\n",
    "p1.scatter(y_train[:,0], DCAA_mlr_regressor.predict(X_train_scaled), color='orange')\n",
    "p1.scatter(y_test[:,0], y_pred_mlr_DCAA, color = \"blue\")\n",
    "p1.plot([-0.5, 7], [-0.5, 7], color='r')\n",
    "p1.set_title('DCAA')\n",
    "p1.set_ylabel(\"Predicted values (log scale)\")\n",
    "\n",
    "p1.text(4,6.2,\"RMSE$_{CV}$ = %f\" %rmse_DCAA_mlr_train, horizontalalignment = \"center\", fontsize = 10)\n",
    "p1.text(4,5.7,\"Q$^{2}$ = %f\" %r2_DCAA_mlr_train, horizontalalignment = \"center\", fontsize = 10)\n",
    "\n",
    "\n",
    "p2 = plt.subplot(132)\n",
    "p2.axis([-0.5, 7, -0.5, 7])\n",
    "p2.scatter(y_train[:,1], TCAA_mlr_regressor.predict(X_train_scaled), color='orange')\n",
    "p2.scatter(y_test[:,1], y_pred_mlr_TCAA, color='blue')\n",
    "p2.plot([-0.5, 7], [-0.5, 7], color='r')\n",
    "p2.set_title('TCAA')\n",
    "p2.set_xlabel(\"Experimental values (log scale)\")\n",
    "\n",
    "p2.text(4,6.2,\"RMSE$_{CV}$ = %f\" %rmse_TCAA_mlr_train, horizontalalignment = \"center\", fontsize = 10)\n",
    "p2.text(4,5.7,\"Q$^{2}$ = %f\" %r2_TCAA_mlr_train, horizontalalignment = \"center\", fontsize = 10)\n",
    "\n",
    "p2.legend((\"_fit\",\"Train\",\"Test\" ), edgecolor = \"black\", mode = \"none\", loc = \"upper left\")\n",
    "\n",
    "\n",
    "plt.text(-2,-2,\"Experimental values (log scale)\", horizontalalignment = \"center\", fontsize = 10)\n",
    "\n",
    "plt.savefig('../Jupyter/results/figures/simplified_MLR_20200331.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA+KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled_train = scaler.fit_transform(X_train)\n",
    "X_scaled_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=30)\n",
    "X_pca = pca.fit_transform(X_scaled_train)\n",
    "sum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### It seems that qsar features have too strong correlationship and serious redundancy.  \n",
    "### Fixed\n",
    "\n",
    "Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_qsar.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DCAA_regressor = KNeighborsRegressor(n_neighbors=3)\n",
    "DCAA_regressor.fit(X_scaled_train, y_train[:,0])\n",
    "\n",
    "TCAA_regressor = KNeighborsRegressor(n_neighbors=3)\n",
    "TCAA_regressor.fit(X_scaled_train, y_train[:,1])\n",
    "\n",
    "HAAFP_regressor = KNeighborsRegressor(n_neighbors=3)\n",
    "HAAFP_regressor.fit(X_scaled_train, y_train[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_DCAA = DCAA_regressor.predict(X_scaled_test)\n",
    "y_pred_TCAA = TCAA_regressor.predict(X_scaled_test)\n",
    "y_pred_HAAFP = HAAFP_regressor.predict(X_scaled_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15, 4))\n",
    "p1 = plt.subplot(131)\n",
    "p1.axis([-2, 7, -2, 7])\n",
    "p1.scatter(np.log(y_train[:,0]+1e-4), np.log(DCAA_regressor.predict(X_scaled)+1e-4), color='black')\n",
    "p1.scatter(np.log(y_test[:,0]+1e-4), np.log(y_pred_DCAA+1e-4))\n",
    "p1.plot([-2, 7], [-2, 7], color='r')\n",
    "p1.set_title('KNN on PCAA (Black: Trainset, Blue: Testset)')\n",
    "p1.set_xlabel('Log True Value')\n",
    "p1.set_ylabel('Log Predicted Value')\n",
    "\n",
    "p2 = plt.subplot(132)\n",
    "p2.axis([-3, 7, -3, 7])\n",
    "p2.scatter(np.log(y_train[:,1]+1e-4), np.log(TCAA_regressor.predict(X_scaled)+1e-4), color='black')\n",
    "p2.scatter(np.log(y_test[:,1]+1e-4), np.log(y_pred_TCAA+1e-4))\n",
    "p2.plot([-3, 7], [-3, 7], color='r')\n",
    "p2.set_title('KNN on TCAA (Black: Trainset, Blue: Testset)')\n",
    "p2.set_xlabel('Log True Value')\n",
    "p2.set_ylabel('Log Predicted Value')\n",
    "\n",
    "p3 = plt.subplot(133)\n",
    "p3.axis([-3, 7, -3, 7])\n",
    "p3.scatter(np.log(y_train[:,2]+1e-4), np.log(HAAFP_regressor.predict(X_scaled)+1e-4), color='black')\n",
    "p3.scatter(np.log(y_test[:,2]+1e-4), np.log(y_pred_HAAFP+1e-4))\n",
    "p3.plot([-3, 7], [-3, 7], color='r')\n",
    "p3.set_title('KNN on HAAFP (Black: Trainset, Blue: Testset)')\n",
    "p3.set_xlabel('Log True Value')\n",
    "p3.set_ylabel('Log Predicted Value')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
